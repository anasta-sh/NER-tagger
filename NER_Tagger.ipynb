{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkqtpB4hC_A"
      },
      "source": [
        "# NER tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUnG00_hYl0"
      },
      "source": [
        "# Data download and description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCe8as2ej9E0",
        "outputId": "ad90049f-54e1-443b-8f74-421b127ad5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n"
          ]
        }
      ],
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.train','eng.train')\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.testa','eng.testa')\n",
        "\n",
        "istream = open('eng.train')\n",
        "for idx, line in enumerate(istream):\n",
        "  print(line.strip())\n",
        "  if idx >=20:\n",
        "    break\n",
        "istream.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2f9l5U7mjLz"
      },
      "source": [
        "The CONLL 2003 dataset encodes each token on a single line followed by its annotation:\n",
        "\n",
        "> (token,tag,chunk,named entity)\n",
        "\n",
        "The NER tags follow the IOB convention:\n",
        "* **I** means **Inside** (part of a named entity);\n",
        "* **B** means **Begin** (starting a new entity);\n",
        "* **O** means **Outside** (not part of a named entity).\n",
        "\n",
        "The **I** and **B** Tag are followed by a specifier (for example, PER=person, ORG=Organisation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mUet-DlpMel"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1l6H_rplBMx"
      },
      "outputs": [],
      "source": [
        "def vocabulary(filename, input_vocab, padding='<pad>', unknown='<unk>'):\n",
        "    # input_vocab is a boolean flag to tell if we extract input or output vocabulary\n",
        "\n",
        "    idx2sym = {}\n",
        "    sym2idx = {}\n",
        "\n",
        "    cur_idx = 0\n",
        "    # Add pad and unk tokens to the vocab\n",
        "    if padding:\n",
        "      idx2sym[cur_idx] = padding\n",
        "      sym2idx[padding] = cur_idx\n",
        "      cur_idx += 1\n",
        "    if unknown:\n",
        "      idx2sym[cur_idx] = unknown\n",
        "      sym2idx[unknown] = cur_idx\n",
        "      cur_idx += 1\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "      for line in file:\n",
        "        line = line.strip()\n",
        "\n",
        "        if not line or line.startswith('-DOCSTART-'):\n",
        "          continue  # Skip empty lines and metadata\n",
        "\n",
        "        parts = line.split()\n",
        "        if input_vocab:\n",
        "          token = parts[0]  # The token is the first column\n",
        "          if token not in sym2idx:\n",
        "            idx2sym[cur_idx] = token\n",
        "            sym2idx[token] = cur_idx\n",
        "            cur_idx += 1\n",
        "        else:\n",
        "          tag = parts[-1]  # The NER tag is the last column\n",
        "          if tag not in sym2idx:\n",
        "            idx2sym[cur_idx] = tag\n",
        "            sym2idx[tag] = cur_idx\n",
        "            cur_idx += 1\n",
        "\n",
        "    return idx2sym, sym2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z-Ve5FqnfRl"
      },
      "outputs": [],
      "source": [
        "def pad_sequence(sequence, pad_size, pad_token):\n",
        "    # returns a list with pad tokens\n",
        "    if sequence is None:\n",
        "      print(\"None sequence is found and replaced with pad tokens.\")\n",
        "      return [pad_token] * pad_size\n",
        "    return sequence[:pad_size] + [pad_token] * (pad_size - len(sequence))\n",
        "\n",
        "def code_sequence(sequence, coding_map, unk_token=None):\n",
        "    # takes a list of strs and returns a list of ints\n",
        "    if sequence is None:\n",
        "      return []\n",
        "    unk_index = coding_map.get(unk_token, None)\n",
        "    return [coding_map.get(token, unk_index) for token in sequence]\n",
        "\n",
        "def decode_sequence(sequence, decoding_map):\n",
        "    # takes a list of ints and returns a list of strs\n",
        "    return [decoding_map.get(index, '<unk>') for index in sequence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW5QysOFpUqJ",
        "outputId": "072aed76-08ea-4785-f34a-8d50a44c3efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EU', 'NNP', 'I-NP', 'I-ORG', '<pad>', '<pad>']\n",
            "[1, 2, 3, 4, 0, 0]\n",
            "['EU', 'NNP', 'I-NP', 'I-ORG', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "# Sample vocab maps\n",
        "sym2idx = {'EU': 1, 'NNP': 2, 'I-NP': 3, 'I-ORG': 4, '<pad>': 0, '<unk>': 5}\n",
        "idx2sym = {v: k for k, v in sym2idx.items()}\n",
        "\n",
        "sequence = ['EU', 'NNP', 'I-NP', 'I-ORG']\n",
        "pad_size = 6\n",
        "padded_seq= pad_sequence(sequence, pad_size, pad_token='<pad>')\n",
        "print(padded_seq)\n",
        "\n",
        "encoded_seq = code_sequence(padded_seq, sym2idx, unk_token='<unk>')\n",
        "print(encoded_seq)\n",
        "\n",
        "# Test decoding\n",
        "decoded_seq = decode_sequence(encoded_seq, idx2sym)\n",
        "print(decoded_seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj9pkrOv6-xS"
      },
      "source": [
        "# Data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP3mMhU58Lgu"
      },
      "outputs": [],
      "source": [
        "def read_conll_tokens(conllfilename):\n",
        "    # reads a CONLL 2003 file and returns a list of sentences.\n",
        "    # A sentence is a list of strings (tokens)\n",
        "    sentences = []\n",
        "    cur_sent = []\n",
        "\n",
        "    with open(conllfilename, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "          if cur_sent:\n",
        "            sentences.append(cur_sent)\n",
        "            cur_sent = []\n",
        "        elif not line.startswith('-DOCSTART-'):\n",
        "          parts = line.split()\n",
        "          cur_sent.append(parts[0])   # token\n",
        "\n",
        "    # Add the last sentence if the file does not end with a newline\n",
        "    if cur_sent:\n",
        "      sentences.append(cur_sent)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def read_conll_tags(conllfilename):\n",
        "    # reads a CONLL 2003 file and returns a list of sentences.\n",
        "    # A sentence is a list of strings (tokens)\n",
        "    sentences = []\n",
        "    cur_sent = []\n",
        "\n",
        "    with open(conllfilename, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "          if cur_sent:\n",
        "            sentences.append(cur_sent)\n",
        "            cur_sent = []\n",
        "        elif not line.startswith('-DOCSTART-'):\n",
        "          parts = line.split()\n",
        "          cur_sent.append(parts[-1])   # NER tag\n",
        "\n",
        "    if cur_sent:\n",
        "      sentences.append(cur_sent)\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1fF55_ls8F6",
        "outputId": "e265f720-cd5e-4524-9fd5-d2994b4547c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n",
            "\n",
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.', '<pad>', '<pad>', '<pad>']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0]\n",
            "[2, 3, 4, 3, 3, 3, 4, 3, 3, 0, 0, 0]\n",
            "\n",
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.', '<pad>', '<pad>', '<pad>']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "# Test on first sentence\n",
        "sample_tokens = tokens[0]\n",
        "sample_tags = tags[0]\n",
        "print(sample_tokens)\n",
        "print(sample_tags)\n",
        "print()\n",
        "\n",
        "# Pad sequences\n",
        "padded_tokens = pad_sequence(sample_tokens, pad_size=12, pad_token='<pad>')\n",
        "padded_tags = pad_sequence(sample_tags, pad_size=12, pad_token='<pad>')\n",
        "print(padded_tokens)\n",
        "print(padded_tags)\n",
        "print()\n",
        "\n",
        "# Encode sequences\n",
        "encoded_tokens = code_sequence(padded_tokens, input_sym2idx, unk_token='<unk>')\n",
        "encoded_tags = code_sequence(padded_tags, output_sym2idx, unk_token='<unk>')\n",
        "print(encoded_tokens)\n",
        "print(encoded_tags)\n",
        "print()\n",
        "\n",
        "# Decode sequences\n",
        "decoded_tokens = decode_sequence(encoded_tokens, input_idx2sym)\n",
        "decoded_tags = decode_sequence(encoded_tags, output_idx2sym)\n",
        "print(decoded_tokens)\n",
        "print(decoded_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0QpXfMmQ0xz"
      },
      "source": [
        "\n",
        "\n",
        "Now we implement the class. You will rely on the helper functions designed above in order to fill in the blanks in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol2Hp2rcGNK9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: \n",
        "                  self.pad_token = parentgenerator.pad_token\n",
        "                  self.unk_token = parentgenerator.unk_token\n",
        "                  self.input_sym2idx = parentgenerator.input_sym2idx\n",
        "                  self.input_idx2sym = parentgenerator.input_idx2sym\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx\n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym\n",
        "              else:                           # Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  # Creates 4 encoding maps from datafile\n",
        "                  self.input_idx2sym,self.input_sym2idx = vocabulary(conllfilename,input_vocab=True,padding=pad_token,unknown=unk_token)\n",
        "                  self.output_idx2sym,self.output_sym2idx = vocabulary(conllfilename,input_vocab=False,padding=pad_token,unknown=unk_token)\n",
        "\n",
        "              # store the conll dataset with sentence structure (a list of lists of strings) in the following fields\n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename)\n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              # Generator function yielding one batch after another. Batches are lists of lists\n",
        "\n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "\n",
        "              N = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              # Data ordering\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              # batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend]\n",
        "                 batch_len = max(len(self.Xtokens[idx]) for idx in batch_idxes)\n",
        "\n",
        "                 seqX = [pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqX = [code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqY = [code_sequence(seq,self.output_sym2idx) for seq in seqY]\n",
        "                 #print(seqX, seqY)\n",
        "\n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpt98v1US9-t"
      },
      "source": [
        "Implementation of the tagger.\n",
        "\n",
        "* Implemention of parameter allocation (the embedding layer, the LSTM (or bi-LSTM) layer and the Linear Layer);\n",
        "* Implemention of the forward method;\n",
        "* Implemention of the train method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1lIuR1kTMDz"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator, embedding_size,hidden_size,device='cuda'):\n",
        "        super(NERtagger, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.allocate_params(traingenerator,device)\n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device):\n",
        "        # Get vocabulary and number of output classes\n",
        "        vocab_size = len(datagenerator.input_sym2idx)  # Size of the input vocabulary\n",
        "        num_classes = len(datagenerator.output_sym2idx)  # Number of output tags\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, self.embedding_size, padding_idx=datagenerator.input_sym2idx[datagenerator.pad_token]).to(device)\n",
        "\n",
        "        # Bi-LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "          input_size=self.embedding_size,\n",
        "          hidden_size=self.hidden_size,\n",
        "          num_layers=1,   # by default\n",
        "          batch_first=True,\n",
        "          bidirectional=True  # Enables Bi-LSTM\n",
        "       ).to(device)\n",
        "\n",
        "        # Linear layer\n",
        "        self.linear = nn.Linear(self.hidden_size * 2, num_classes).to(device)  # Bi-LSTM output is 2 * hidden_size\n",
        "\n",
        "      def forward(self,Xinput):\n",
        "        # prediction steps\n",
        "        # Embedding layer\n",
        "        embeddings = self.embedding(Xinput)  # Shape: (batch_size, seq_len, embedding_size)\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_out, _ = self.lstm(embeddings)  # Shape: (batch_size, seq_len, hidden_size * 2)\n",
        "\n",
        "        # Linear layer\n",
        "        logits = self.linear(lstm_out)  # Shape: (batch_size, seq_len, num_classes)\n",
        "\n",
        "        return logits\n",
        "\n",
        "      def train_model(self,traingenerator,validgenerator,epochs,batch_size,device='cuda',learning_rate=0.001):\n",
        "\n",
        "        self.minloss = 10000000 # the min loss found so far on validation data\n",
        "\n",
        "        self.to(device)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "          print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "          self.train()  # Set model to training mode\n",
        "\n",
        "          batch_losses = []\n",
        "          batch_accuracies = []\n",
        "\n",
        "          for seqX, seqY in traingenerator.generate_batches(batch_size):\n",
        "            X = torch.LongTensor(seqX).to(device)\n",
        "            Y = torch.LongTensor(seqY).to(device)\n",
        "\n",
        "            Yhat = self.forward(X)\n",
        "\n",
        "            # Flatten outputs for loss computation\n",
        "            batch_size, seq_len = Y.shape\n",
        "            Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "            Y = Y.view(batch_size * seq_len)\n",
        "\n",
        "            # Loss computation\n",
        "            loss = loss_fnc(Yhat, Y)\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy computation\n",
        "            mask = (Y != pad_index)\n",
        "            Yargmax = torch.argmax(Yhat, dim=1)\n",
        "            correct = torch.sum((Yargmax == Y) * mask)\n",
        "            total = torch.sum(mask)\n",
        "            batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "          # Epoch summary\n",
        "          train_loss = sum(batch_losses) / len(batch_losses)\n",
        "          train_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
        "          print(f\"[train] Epoch {epoch} mean loss = {train_loss:.4f} | mean accuracy = {train_accuracy:.4f}\")\n",
        "\n",
        "          # Validate model\n",
        "          valid_loss, valid_accuracy = self.validate(validgenerator, batch_size, device, save_min_model=True)\n",
        "          print(f\"[valid] Epoch {epoch} mean loss = {valid_loss:.4f} | mean accuracy = {valid_accuracy:.4f}\")\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cuda',save_min_model=False):\n",
        "\n",
        "          batch_accurracies = []\n",
        "          batch_losses = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY) in datagenerator.generate_batches(batch_size):\n",
        "                with torch.no_grad():\n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device)\n",
        "\n",
        "                  Yhat = self.forward(X)\n",
        "\n",
        "                  #Flattening and loss computation\n",
        "                  batch_size,seq_len = Y.shape\n",
        "                  Yhat = Yhat.view(batch_size*seq_len,-1)\n",
        "                  Y = Y.view(batch_size*seq_len)\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  total = torch.sum(mask)\n",
        "                  batch_accurracies.append(float(correct)/float(total))\n",
        "\n",
        "          L = len(batch_losses)\n",
        "          valid_loss = sum(batch_losses)/L\n",
        "          valid_accuracy = sum(batch_accurracies) / L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "          return valid_loss, valid_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI8Z9iuP0j4K"
      },
      "outputs": [],
      "source": [
        "# Load the full dataset\n",
        "full_trainset = DataGenerator('eng.train')\n",
        "\n",
        "# Create a small sample from the full dataset\n",
        "sample_size = 15  # Choose a small sample size for testing\n",
        "small_trainset = DataGenerator('eng.train')\n",
        "\n",
        "# Limit the Xtokens and Ytokens to the first few examples\n",
        "small_trainset.Xtokens = full_trainset.Xtokens[:sample_size]\n",
        "small_trainset.Ytokens = full_trainset.Ytokens[:sample_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHjt_9j79cHh",
        "outputId": "4985c924-b0cd-404a-805e-a392820173b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/4\n",
            "[train] Epoch 1 mean loss = 2.2258 | mean accuracy = 0.4242\n",
            "[valid] Epoch 1 mean loss = 2.1146 | mean accuracy = 0.7474\n",
            "\n",
            "Epoch 2/4\n",
            "[train] Epoch 2 mean loss = 2.0262 | mean accuracy = 0.7904\n",
            "[valid] Epoch 2 mean loss = 1.8731 | mean accuracy = 0.8416\n",
            "\n",
            "Epoch 3/4\n",
            "[train] Epoch 3 mean loss = 1.7318 | mean accuracy = 0.8416\n",
            "[valid] Epoch 3 mean loss = 1.4944 | mean accuracy = 0.8434\n",
            "\n",
            "Epoch 4/4\n",
            "[train] Epoch 4 mean loss = 1.1980 | mean accuracy = 0.8434\n",
            "[valid] Epoch 4 mean loss = 0.8577 | mean accuracy = 0.8434\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "tagger = NERtagger(small_trainset, embedding_size=64, hidden_size=128, device='cuda')\n",
        "\n",
        "# Train on the small dataset\n",
        "tagger.train_model(traingenerator=small_trainset, validgenerator=small_trainset, epochs=4, batch_size=4, device='cuda', learning_rate=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4SoEEEf3uM4",
        "outputId": "3494b2ad-86a1-46e1-a13f-7f3e17c85c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.7072 | mean accuracy = 0.7990\n",
            "[valid] Epoch 1 mean loss = 0.5355 | mean accuracy = 0.8359\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.3694 | mean accuracy = 0.8854\n",
            "[valid] Epoch 2 mean loss = 0.3516 | mean accuracy = 0.8934\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.2167 | mean accuracy = 0.9320\n",
            "[valid] Epoch 3 mean loss = 0.2610 | mean accuracy = 0.9199\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.1244 | mean accuracy = 0.9615\n",
            "[valid] Epoch 4 mean loss = 0.2249 | mean accuracy = 0.9343\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0828 | mean accuracy = 0.9741\n",
            "[valid] Epoch 5 mean loss = 0.2328 | mean accuracy = 0.9338\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0350 | mean accuracy = 0.9892\n",
            "[valid] Epoch 6 mean loss = 0.2695 | mean accuracy = 0.9304\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0156 | mean accuracy = 0.9954\n",
            "[valid] Epoch 7 mean loss = 0.2839 | mean accuracy = 0.9322\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0087 | mean accuracy = 0.9973\n",
            "[valid] Epoch 8 mean loss = 0.3285 | mean accuracy = 0.9300\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0058 | mean accuracy = 0.9981\n",
            "[valid] Epoch 9 mean loss = 0.3208 | mean accuracy = 0.9410\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0043 | mean accuracy = 0.9987\n",
            "[valid] Epoch 10 mean loss = 0.3519 | mean accuracy = 0.9395\n"
          ]
        }
      ],
      "source": [
        "# Train on the full dataset\n",
        "trainset = DataGenerator('eng.train')\n",
        "validset = DataGenerator('eng.testa',parentgenerator = trainset)\n",
        "tagger   = NERtagger(trainset,embedding_size=64,hidden_size=128,device='cuda')\n",
        "tagger.train_model(traingenerator=trainset,validgenerator=validset,epochs=10,batch_size=32,device='cuda',learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djvs8vvpe81g"
      },
      "source": [
        "# Search for hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUJ5IbH_IzJQ",
        "outputId": "28f95951-98a9-43ff-b769-46761fb238e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEe2Kgn8IvTF",
        "outputId": "5683c9f4-eafc-40b8-ac2c-de199d3043e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:40,809] A new study created in memory with name: no-name-68447067-5b2c-4bb3-9555-004b298f84f1\n",
            "<ipython-input-16-6c99836de519>:21: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=256, learning_rate=0.0005212933350473318, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2901 | mean accuracy = 0.1721\n",
            "[valid] Epoch 1 mean loss = 2.2626 | mean accuracy = 0.3625\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2114 | mean accuracy = 0.7034\n",
            "[valid] Epoch 2 mean loss = 2.1904 | mean accuracy = 0.7472\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.0944 | mean accuracy = 0.8294\n",
            "[valid] Epoch 3 mean loss = 2.0929 | mean accuracy = 0.7459\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 1.8091 | mean accuracy = 0.8189\n",
            "[valid] Epoch 4 mean loss = 1.8007 | mean accuracy = 0.7600\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 1.2415 | mean accuracy = 0.8054\n",
            "[valid] Epoch 5 mean loss = 1.2991 | mean accuracy = 0.7707\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.7981 | mean accuracy = 0.8047\n",
            "[valid] Epoch 6 mean loss = 1.1193 | mean accuracy = 0.7656\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.7430 | mean accuracy = 0.8056\n",
            "[valid] Epoch 7 mean loss = 1.0803 | mean accuracy = 0.7695\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.6841 | mean accuracy = 0.8048\n",
            "[valid] Epoch 8 mean loss = 1.0656 | mean accuracy = 0.7549\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:41,966] Trial 0 finished with value: 0.8417664170265198 and parameters: {'embedding_size': 32, 'hidden_size': 256, 'learning_rate': 0.0005212933350473318, 'batch_size': 64}. Best is trial 0 with value: 0.8417664170265198.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.6438 | mean accuracy = 0.8060\n",
            "[valid] Epoch 9 mean loss = 1.0591 | mean accuracy = 0.7506\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.6071 | mean accuracy = 0.8180\n",
            "[valid] Epoch 10 mean loss = 1.0580 | mean accuracy = 0.7504\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=64, learning_rate=0.0023836895341926394, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2154 | mean accuracy = 0.3679\n",
            "[valid] Epoch 1 mean loss = 2.0755 | mean accuracy = 0.6899\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.1800 | mean accuracy = 0.8399\n",
            "[valid] Epoch 2 mean loss = 1.0087 | mean accuracy = 0.7852\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6489 | mean accuracy = 0.8212\n",
            "[valid] Epoch 3 mean loss = 0.9118 | mean accuracy = 0.7946\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.5128 | mean accuracy = 0.8599\n",
            "[valid] Epoch 4 mean loss = 0.8890 | mean accuracy = 0.7955\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3894 | mean accuracy = 0.8888\n",
            "[valid] Epoch 5 mean loss = 0.8900 | mean accuracy = 0.7901\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2729 | mean accuracy = 0.9237\n",
            "[valid] Epoch 6 mean loss = 0.9137 | mean accuracy = 0.7869\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1821 | mean accuracy = 0.9512\n",
            "[valid] Epoch 7 mean loss = 0.9516 | mean accuracy = 0.7792\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1288 | mean accuracy = 0.9713\n",
            "[valid] Epoch 8 mean loss = 1.0512 | mean accuracy = 0.7843\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1018 | mean accuracy = 0.9813\n",
            "[valid] Epoch 9 mean loss = 1.2239 | mean accuracy = 0.7881\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:42,940] Trial 1 finished with value: 1.1463214755058289 and parameters: {'embedding_size': 64, 'hidden_size': 64, 'learning_rate': 0.0023836895341926394, 'batch_size': 16}. Best is trial 0 with value: 0.8417664170265198.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.0802 | mean accuracy = 0.9870\n",
            "[valid] Epoch 10 mean loss = 1.1894 | mean accuracy = 0.7955\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.00014219738640898426, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.3000 | mean accuracy = 0.0692\n",
            "[valid] Epoch 1 mean loss = 2.2809 | mean accuracy = 0.0992\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2853 | mean accuracy = 0.0890\n",
            "[valid] Epoch 2 mean loss = 2.2696 | mean accuracy = 0.1342\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.2675 | mean accuracy = 0.1433\n",
            "[valid] Epoch 3 mean loss = 2.2563 | mean accuracy = 0.2075\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 2.2400 | mean accuracy = 0.2859\n",
            "[valid] Epoch 4 mean loss = 2.2365 | mean accuracy = 0.2988\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 2.1785 | mean accuracy = 0.6501\n",
            "[valid] Epoch 5 mean loss = 2.1657 | mean accuracy = 0.5676\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 2.0630 | mean accuracy = 0.8129\n",
            "[valid] Epoch 6 mean loss = 2.0714 | mean accuracy = 0.6948\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 1.8738 | mean accuracy = 0.8189\n",
            "[valid] Epoch 7 mean loss = 1.8962 | mean accuracy = 0.7652\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 1.3794 | mean accuracy = 0.8162\n",
            "[valid] Epoch 8 mean loss = 1.4383 | mean accuracy = 0.7801\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:43,791] Trial 2 finished with value: 0.986338883638382 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.00014219738640898426, 'batch_size': 64}. Best is trial 0 with value: 0.8417664170265198.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 1.0426 | mean accuracy = 0.8059\n",
            "[valid] Epoch 9 mean loss = 1.3236 | mean accuracy = 0.7812\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.9259 | mean accuracy = 0.8058\n",
            "[valid] Epoch 10 mean loss = 1.2726 | mean accuracy = 0.7801\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=128, learning_rate=0.003173919738405495, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.1571 | mean accuracy = 0.5635\n",
            "[valid] Epoch 1 mean loss = 1.9738 | mean accuracy = 0.7744\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.9212 | mean accuracy = 0.8086\n",
            "[valid] Epoch 2 mean loss = 1.0367 | mean accuracy = 0.7706\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6497 | mean accuracy = 0.8347\n",
            "[valid] Epoch 3 mean loss = 0.9746 | mean accuracy = 0.7347\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.5611 | mean accuracy = 0.8737\n",
            "[valid] Epoch 4 mean loss = 0.9188 | mean accuracy = 0.7764\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.4390 | mean accuracy = 0.8834\n",
            "[valid] Epoch 5 mean loss = 0.8968 | mean accuracy = 0.7701\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.3152 | mean accuracy = 0.9123\n",
            "[valid] Epoch 6 mean loss = 0.9514 | mean accuracy = 0.7431\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.2374 | mean accuracy = 0.9406\n",
            "[valid] Epoch 7 mean loss = 1.0237 | mean accuracy = 0.7199\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1929 | mean accuracy = 0.9529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:44,754] Trial 3 finished with value: 1.0789838284254074 and parameters: {'embedding_size': 32, 'hidden_size': 128, 'learning_rate': 0.003173919738405495, 'batch_size': 32}. Best is trial 0 with value: 0.8417664170265198.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 8 mean loss = 0.9944 | mean accuracy = 0.7686\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1352 | mean accuracy = 0.9647\n",
            "[valid] Epoch 9 mean loss = 1.0974 | mean accuracy = 0.7573\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0978 | mean accuracy = 0.9773\n",
            "[valid] Epoch 10 mean loss = 1.1318 | mean accuracy = 0.7463\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=256, learning_rate=0.00021056118373457603, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.3016 | mean accuracy = 0.0975\n",
            "[valid] Epoch 1 mean loss = 2.2818 | mean accuracy = 0.1472\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.1467 | mean accuracy = 0.6098\n",
            "[valid] Epoch 2 mean loss = 2.0805 | mean accuracy = 0.7128\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.5961 | mean accuracy = 0.8218\n",
            "[valid] Epoch 3 mean loss = 1.4168 | mean accuracy = 0.7756\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.9940 | mean accuracy = 0.8177\n",
            "[valid] Epoch 4 mean loss = 1.2566 | mean accuracy = 0.7753\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.7461 | mean accuracy = 0.8169\n",
            "[valid] Epoch 5 mean loss = 1.1619 | mean accuracy = 0.7954\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.6861 | mean accuracy = 0.8233\n",
            "[valid] Epoch 6 mean loss = 1.1138 | mean accuracy = 0.7862\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.6305 | mean accuracy = 0.8387\n",
            "[valid] Epoch 7 mean loss = 1.0887 | mean accuracy = 0.7854\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.5875 | mean accuracy = 0.8493\n",
            "[valid] Epoch 8 mean loss = 1.0684 | mean accuracy = 0.7851\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.5487 | mean accuracy = 0.8755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:46,423] Trial 4 finished with value: 0.8287050575017929 and parameters: {'embedding_size': 128, 'hidden_size': 256, 'learning_rate': 0.00021056118373457603, 'batch_size': 32}. Best is trial 4 with value: 0.8287050575017929.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 9 mean loss = 1.0543 | mean accuracy = 0.7853\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.5100 | mean accuracy = 0.8757\n",
            "[valid] Epoch 10 mean loss = 1.0435 | mean accuracy = 0.7805\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=64, learning_rate=0.0036115471402767786, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.1895 | mean accuracy = 0.4729\n",
            "[valid] Epoch 1 mean loss = 2.0572 | mean accuracy = 0.7108\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.1091 | mean accuracy = 0.8243\n",
            "[valid] Epoch 2 mean loss = 0.9719 | mean accuracy = 0.8057\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.7096 | mean accuracy = 0.8262\n",
            "[valid] Epoch 3 mean loss = 0.9287 | mean accuracy = 0.8050\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.5709 | mean accuracy = 0.8313\n",
            "[valid] Epoch 4 mean loss = 0.8835 | mean accuracy = 0.8048\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.4749 | mean accuracy = 0.8739\n",
            "[valid] Epoch 5 mean loss = 0.8840 | mean accuracy = 0.7861\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.3813 | mean accuracy = 0.8955\n",
            "[valid] Epoch 6 mean loss = 0.8838 | mean accuracy = 0.7629\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.2844 | mean accuracy = 0.9239\n",
            "[valid] Epoch 7 mean loss = 0.9297 | mean accuracy = 0.7430\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.2000 | mean accuracy = 0.9514\n",
            "[valid] Epoch 8 mean loss = 0.9514 | mean accuracy = 0.7376\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:47,324] Trial 5 finished with value: 1.0371297001838684 and parameters: {'embedding_size': 32, 'hidden_size': 64, 'learning_rate': 0.0036115471402767786, 'batch_size': 32}. Best is trial 4 with value: 0.8287050575017929.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.1399 | mean accuracy = 0.9652\n",
            "[valid] Epoch 9 mean loss = 1.0101 | mean accuracy = 0.7455\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.1206 | mean accuracy = 0.9690\n",
            "[valid] Epoch 10 mean loss = 1.0856 | mean accuracy = 0.7618\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0006365672636902998, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2711 | mean accuracy = 0.1966\n",
            "[valid] Epoch 1 mean loss = 2.2431 | mean accuracy = 0.3202\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.9125 | mean accuracy = 0.7684\n",
            "[valid] Epoch 2 mean loss = 1.6126 | mean accuracy = 0.7849\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.0446 | mean accuracy = 0.8050\n",
            "[valid] Epoch 3 mean loss = 1.1678 | mean accuracy = 0.7853\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.7246 | mean accuracy = 0.8054\n",
            "[valid] Epoch 4 mean loss = 1.0574 | mean accuracy = 0.8051\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.6662 | mean accuracy = 0.8112\n",
            "[valid] Epoch 5 mean loss = 1.0184 | mean accuracy = 0.8057\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.6077 | mean accuracy = 0.8310\n",
            "[valid] Epoch 6 mean loss = 0.9959 | mean accuracy = 0.8048\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.5638 | mean accuracy = 0.8570\n",
            "[valid] Epoch 7 mean loss = 0.9826 | mean accuracy = 0.7957\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.5151 | mean accuracy = 0.8704\n",
            "[valid] Epoch 8 mean loss = 0.9794 | mean accuracy = 0.7935\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.4698 | mean accuracy = 0.8768\n",
            "[valid] Epoch 9 mean loss = 0.9799 | mean accuracy = 0.7834\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:48,437] Trial 6 finished with value: 0.8238050639629364 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0006365672636902998, 'batch_size': 32}. Best is trial 6 with value: 0.8238050639629364.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.4210 | mean accuracy = 0.8876\n",
            "[valid] Epoch 10 mean loss = 0.9789 | mean accuracy = 0.7764\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.00010395347128941034, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2966 | mean accuracy = 0.1018\n",
            "[valid] Epoch 1 mean loss = 2.2903 | mean accuracy = 0.1264\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2497 | mean accuracy = 0.2904\n",
            "[valid] Epoch 2 mean loss = 2.2357 | mean accuracy = 0.4494\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.1754 | mean accuracy = 0.6649\n",
            "[valid] Epoch 3 mean loss = 2.1752 | mean accuracy = 0.6451\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 2.0882 | mean accuracy = 0.7880\n",
            "[valid] Epoch 4 mean loss = 2.0979 | mean accuracy = 0.7255\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 1.9646 | mean accuracy = 0.8209\n",
            "[valid] Epoch 5 mean loss = 1.9835 | mean accuracy = 0.7438\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 1.7376 | mean accuracy = 0.8159\n",
            "[valid] Epoch 6 mean loss = 1.7565 | mean accuracy = 0.7608\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 1.2590 | mean accuracy = 0.8178\n",
            "[valid] Epoch 7 mean loss = 1.3841 | mean accuracy = 0.7555\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 1.0558 | mean accuracy = 0.8155\n",
            "[valid] Epoch 8 mean loss = 1.3018 | mean accuracy = 0.7650\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.9679 | mean accuracy = 0.8152\n",
            "[valid] Epoch 9 mean loss = 1.2580 | mean accuracy = 0.7752\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:49,552] Trial 7 finished with value: 1.137094599860055 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.00010395347128941034, 'batch_size': 16}. Best is trial 6 with value: 0.8238050639629364.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.9151 | mean accuracy = 0.8213\n",
            "[valid] Epoch 10 mean loss = 1.2201 | mean accuracy = 0.7751\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=128, learning_rate=0.00036580791472353726, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.3032 | mean accuracy = 0.0516\n",
            "[valid] Epoch 1 mean loss = 2.2965 | mean accuracy = 0.0444\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2694 | mean accuracy = 0.1870\n",
            "[valid] Epoch 2 mean loss = 2.2634 | mean accuracy = 0.1919\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.2217 | mean accuracy = 0.5086\n",
            "[valid] Epoch 3 mean loss = 2.2255 | mean accuracy = 0.4965\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 2.1493 | mean accuracy = 0.7479\n",
            "[valid] Epoch 4 mean loss = 2.1570 | mean accuracy = 0.7273\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 1.7928 | mean accuracy = 0.8128\n",
            "[valid] Epoch 5 mean loss = 1.5637 | mean accuracy = 0.7751\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 1.1109 | mean accuracy = 0.8050\n",
            "[valid] Epoch 6 mean loss = 1.2441 | mean accuracy = 0.7845\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.8763 | mean accuracy = 0.8056\n",
            "[valid] Epoch 7 mean loss = 1.1354 | mean accuracy = 0.7856\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.8039 | mean accuracy = 0.8165\n",
            "[valid] Epoch 8 mean loss = 1.0780 | mean accuracy = 0.7795\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:50,335] Trial 8 finished with value: 0.8193902969360352 and parameters: {'embedding_size': 32, 'hidden_size': 128, 'learning_rate': 0.00036580791472353726, 'batch_size': 64}. Best is trial 8 with value: 0.8193902969360352.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.7505 | mean accuracy = 0.8163\n",
            "[valid] Epoch 9 mean loss = 1.0375 | mean accuracy = 0.7799\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.7123 | mean accuracy = 0.8159\n",
            "[valid] Epoch 10 mean loss = 1.0066 | mean accuracy = 0.7814\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=128, learning_rate=0.00020018717938203651, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2944 | mean accuracy = 0.0286\n",
            "[valid] Epoch 1 mean loss = 2.2841 | mean accuracy = 0.0608\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2759 | mean accuracy = 0.0966\n",
            "[valid] Epoch 2 mean loss = 2.2689 | mean accuracy = 0.1213\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.2520 | mean accuracy = 0.2586\n",
            "[valid] Epoch 3 mean loss = 2.2490 | mean accuracy = 0.2973\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 2.2164 | mean accuracy = 0.4822\n",
            "[valid] Epoch 4 mean loss = 2.2164 | mean accuracy = 0.5139\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 2.1138 | mean accuracy = 0.7248\n",
            "[valid] Epoch 5 mean loss = 2.0715 | mean accuracy = 0.7324\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 1.7857 | mean accuracy = 0.8041\n",
            "[valid] Epoch 6 mean loss = 1.6849 | mean accuracy = 0.7754\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 1.2058 | mean accuracy = 0.8054\n",
            "[valid] Epoch 7 mean loss = 1.3142 | mean accuracy = 0.7792\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 1.0015 | mean accuracy = 0.8051\n",
            "[valid] Epoch 8 mean loss = 1.2402 | mean accuracy = 0.7865\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.9112 | mean accuracy = 0.8053\n",
            "[valid] Epoch 9 mean loss = 1.1869 | mean accuracy = 0.7856\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:51,138] Trial 9 finished with value: 0.9067936837673187 and parameters: {'embedding_size': 32, 'hidden_size': 128, 'learning_rate': 0.00020018717938203651, 'batch_size': 64}. Best is trial 8 with value: 0.8193902969360352.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.8540 | mean accuracy = 0.8055\n",
            "[valid] Epoch 10 mean loss = 1.1455 | mean accuracy = 0.7857\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=64, learning_rate=0.0014580596695547177, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.3175 | mean accuracy = 0.0930\n",
            "[valid] Epoch 1 mean loss = 2.2644 | mean accuracy = 0.1639\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.1946 | mean accuracy = 0.3805\n",
            "[valid] Epoch 2 mean loss = 2.1642 | mean accuracy = 0.4420\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.0176 | mean accuracy = 0.6816\n",
            "[valid] Epoch 3 mean loss = 2.0101 | mean accuracy = 0.6495\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 1.6550 | mean accuracy = 0.8278\n",
            "[valid] Epoch 4 mean loss = 1.6751 | mean accuracy = 0.7487\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.9389 | mean accuracy = 0.8460\n",
            "[valid] Epoch 5 mean loss = 1.0950 | mean accuracy = 0.7754\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.5834 | mean accuracy = 0.8426\n",
            "[valid] Epoch 6 mean loss = 1.0296 | mean accuracy = 0.7758\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.4596 | mean accuracy = 0.8644\n",
            "[valid] Epoch 7 mean loss = 1.0148 | mean accuracy = 0.7750\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.3541 | mean accuracy = 0.9029\n",
            "[valid] Epoch 8 mean loss = 1.0009 | mean accuracy = 0.7633\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.2545 | mean accuracy = 0.9299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:52,588] Trial 10 finished with value: 0.8495599031448364 and parameters: {'embedding_size': 128, 'hidden_size': 64, 'learning_rate': 0.0014580596695547177, 'batch_size': 64}. Best is trial 8 with value: 0.8193902969360352.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 9 mean loss = 0.9971 | mean accuracy = 0.7610\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.1770 | mean accuracy = 0.9562\n",
            "[valid] Epoch 10 mean loss = 0.9987 | mean accuracy = 0.7673\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.000609549418897796, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2760 | mean accuracy = 0.1560\n",
            "[valid] Epoch 1 mean loss = 2.2437 | mean accuracy = 0.3351\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.9923 | mean accuracy = 0.7515\n",
            "[valid] Epoch 2 mean loss = 1.7693 | mean accuracy = 0.7776\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.1112 | mean accuracy = 0.8208\n",
            "[valid] Epoch 3 mean loss = 1.1983 | mean accuracy = 0.7852\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.7477 | mean accuracy = 0.8200\n",
            "[valid] Epoch 4 mean loss = 1.0803 | mean accuracy = 0.7845\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.6798 | mean accuracy = 0.8362\n",
            "[valid] Epoch 5 mean loss = 1.0324 | mean accuracy = 0.7997\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.6159 | mean accuracy = 0.8580\n",
            "[valid] Epoch 6 mean loss = 0.9990 | mean accuracy = 0.7988\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.5673 | mean accuracy = 0.8621\n",
            "[valid] Epoch 7 mean loss = 0.9861 | mean accuracy = 0.7921\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.5141 | mean accuracy = 0.8728\n",
            "[valid] Epoch 8 mean loss = 0.9725 | mean accuracy = 0.7939\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.4622 | mean accuracy = 0.8799\n",
            "[valid] Epoch 9 mean loss = 0.9685 | mean accuracy = 0.7857\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:53,918] Trial 11 finished with value: 0.8099141269922256 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.000609549418897796, 'batch_size': 32}. Best is trial 11 with value: 0.8099141269922256.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.4081 | mean accuracy = 0.8852\n",
            "[valid] Epoch 10 mean loss = 0.9767 | mean accuracy = 0.7779\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=128, learning_rate=0.00038012851497897356, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2915 | mean accuracy = 0.0848\n",
            "[valid] Epoch 1 mean loss = 2.2747 | mean accuracy = 0.2335\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.2570 | mean accuracy = 0.3055\n",
            "[valid] Epoch 2 mean loss = 2.2413 | mean accuracy = 0.4836\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 2.2104 | mean accuracy = 0.6063\n",
            "[valid] Epoch 3 mean loss = 2.2020 | mean accuracy = 0.6447\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 2.1361 | mean accuracy = 0.7667\n",
            "[valid] Epoch 4 mean loss = 2.1301 | mean accuracy = 0.7222\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 1.7599 | mean accuracy = 0.8037\n",
            "[valid] Epoch 5 mean loss = 1.4856 | mean accuracy = 0.7703\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 1.1122 | mean accuracy = 0.8048\n",
            "[valid] Epoch 6 mean loss = 1.2575 | mean accuracy = 0.7905\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.8701 | mean accuracy = 0.8055\n",
            "[valid] Epoch 7 mean loss = 1.1471 | mean accuracy = 0.7907\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.8054 | mean accuracy = 0.8044\n",
            "[valid] Epoch 8 mean loss = 1.0985 | mean accuracy = 0.7907\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:54,704] Trial 12 finished with value: 0.8332357704639435 and parameters: {'embedding_size': 32, 'hidden_size': 128, 'learning_rate': 0.00038012851497897356, 'batch_size': 64}. Best is trial 11 with value: 0.8099141269922256.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.7577 | mean accuracy = 0.8063\n",
            "[valid] Epoch 9 mean loss = 1.0701 | mean accuracy = 0.7904\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.7251 | mean accuracy = 0.8049\n",
            "[valid] Epoch 10 mean loss = 1.0484 | mean accuracy = 0.7903\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0010851759746442, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2723 | mean accuracy = 0.2115\n",
            "[valid] Epoch 1 mean loss = 2.2261 | mean accuracy = 0.3575\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.5116 | mean accuracy = 0.8151\n",
            "[valid] Epoch 2 mean loss = 1.1835 | mean accuracy = 0.7682\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.7192 | mean accuracy = 0.8107\n",
            "[valid] Epoch 3 mean loss = 1.0349 | mean accuracy = 0.7784\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.6365 | mean accuracy = 0.8369\n",
            "[valid] Epoch 4 mean loss = 0.9773 | mean accuracy = 0.7782\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.5321 | mean accuracy = 0.8582\n",
            "[valid] Epoch 5 mean loss = 0.9577 | mean accuracy = 0.7757\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.4543 | mean accuracy = 0.8771\n",
            "[valid] Epoch 6 mean loss = 0.9457 | mean accuracy = 0.7644\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.3730 | mean accuracy = 0.8904\n",
            "[valid] Epoch 7 mean loss = 0.9449 | mean accuracy = 0.7611\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.2976 | mean accuracy = 0.9199\n",
            "[valid] Epoch 8 mean loss = 0.9622 | mean accuracy = 0.7515\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:55,812] Trial 13 finished with value: 0.8629544824361801 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0010851759746442, 'batch_size': 32}. Best is trial 11 with value: 0.8099141269922256.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.2392 | mean accuracy = 0.9312\n",
            "[valid] Epoch 9 mean loss = 0.9814 | mean accuracy = 0.7152\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.1885 | mean accuracy = 0.9550\n",
            "[valid] Epoch 10 mean loss = 1.0029 | mean accuracy = 0.7265\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=256, learning_rate=0.006769400276704751, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.2833 | mean accuracy = 0.7404\n",
            "[valid] Epoch 1 mean loss = 1.0422 | mean accuracy = 0.7899\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.4853 | mean accuracy = 0.8608\n",
            "[valid] Epoch 2 mean loss = 0.8991 | mean accuracy = 0.7611\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.1296 | mean accuracy = 0.9705\n",
            "[valid] Epoch 3 mean loss = 0.9740 | mean accuracy = 0.7695\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0339 | mean accuracy = 0.9896\n",
            "[valid] Epoch 4 mean loss = 1.0572 | mean accuracy = 0.7700\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0209 | mean accuracy = 0.9940\n",
            "[valid] Epoch 5 mean loss = 1.2991 | mean accuracy = 0.7817\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0076 | mean accuracy = 0.9993\n",
            "[valid] Epoch 6 mean loss = 1.1822 | mean accuracy = 0.7466\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0018 | mean accuracy = 1.0000\n",
            "[valid] Epoch 7 mean loss = 1.2922 | mean accuracy = 0.7713\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0007 | mean accuracy = 1.0000\n",
            "[valid] Epoch 8 mean loss = 1.2891 | mean accuracy = 0.7549\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0005 | mean accuracy = 1.0000\n",
            "[valid] Epoch 9 mean loss = 1.3167 | mean accuracy = 0.7553\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:57,218] Trial 14 finished with value: 1.3474999581064497 and parameters: {'embedding_size': 128, 'hidden_size': 256, 'learning_rate': 0.006769400276704751, 'batch_size': 16}. Best is trial 11 with value: 0.8099141269922256.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 10 mean loss = 0.0004 | mean accuracy = 1.0000\n",
            "[valid] Epoch 10 mean loss = 1.3445 | mean accuracy = 0.7630\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0003831070427482731, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2215 | mean accuracy = 0.5021\n",
            "[valid] Epoch 1 mean loss = 2.1876 | mean accuracy = 0.6442\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.0523 | mean accuracy = 0.7895\n",
            "[valid] Epoch 2 mean loss = 1.9548 | mean accuracy = 0.7796\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.3635 | mean accuracy = 0.8366\n",
            "[valid] Epoch 3 mean loss = 1.2861 | mean accuracy = 0.8054\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.9162 | mean accuracy = 0.8212\n",
            "[valid] Epoch 4 mean loss = 1.1665 | mean accuracy = 0.8055\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.7720 | mean accuracy = 0.8202\n",
            "[valid] Epoch 5 mean loss = 1.1064 | mean accuracy = 0.8057\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.7101 | mean accuracy = 0.8269\n",
            "[valid] Epoch 6 mean loss = 1.0731 | mean accuracy = 0.8053\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.6608 | mean accuracy = 0.8356\n",
            "[valid] Epoch 7 mean loss = 1.0452 | mean accuracy = 0.7960\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.6157 | mean accuracy = 0.8418\n",
            "[valid] Epoch 8 mean loss = 1.0369 | mean accuracy = 0.7998\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.5773 | mean accuracy = 0.8578\n",
            "[valid] Epoch 9 mean loss = 1.0160 | mean accuracy = 0.8011\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.5405 | mean accuracy = 0.8617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:58,304] Trial 15 finished with value: 0.7881987541913986 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0003831070427482731, 'batch_size': 32}. Best is trial 15 with value: 0.7881987541913986.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 1.0062 | mean accuracy = 0.8011\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0007323806892369036, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.3013 | mean accuracy = 0.0757\n",
            "[valid] Epoch 1 mean loss = 2.2352 | mean accuracy = 0.3141\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.8012 | mean accuracy = 0.7427\n",
            "[valid] Epoch 2 mean loss = 1.2823 | mean accuracy = 0.7954\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.9711 | mean accuracy = 0.8161\n",
            "[valid] Epoch 3 mean loss = 1.1075 | mean accuracy = 0.8048\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.7199 | mean accuracy = 0.8167\n",
            "[valid] Epoch 4 mean loss = 1.0057 | mean accuracy = 0.8051\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.6498 | mean accuracy = 0.8368\n",
            "[valid] Epoch 5 mean loss = 0.9681 | mean accuracy = 0.8059\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.5945 | mean accuracy = 0.8411\n",
            "[valid] Epoch 6 mean loss = 0.9423 | mean accuracy = 0.8046\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.5404 | mean accuracy = 0.8687\n",
            "[valid] Epoch 7 mean loss = 0.9227 | mean accuracy = 0.7928\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.4886 | mean accuracy = 0.8728\n",
            "[valid] Epoch 8 mean loss = 0.9155 | mean accuracy = 0.7925\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:20:59,385] Trial 16 finished with value: 0.7878151386976242 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0007323806892369036, 'batch_size': 32}. Best is trial 16 with value: 0.7878151386976242.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.4378 | mean accuracy = 0.8797\n",
            "[valid] Epoch 9 mean loss = 0.9166 | mean accuracy = 0.7886\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.3814 | mean accuracy = 0.8936\n",
            "[valid] Epoch 10 mean loss = 0.9282 | mean accuracy = 0.7866\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0016596900409684482, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2456 | mean accuracy = 0.3190\n",
            "[valid] Epoch 1 mean loss = 2.1458 | mean accuracy = 0.6637\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.2653 | mean accuracy = 0.8171\n",
            "[valid] Epoch 2 mean loss = 1.0582 | mean accuracy = 0.7609\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6937 | mean accuracy = 0.8209\n",
            "[valid] Epoch 3 mean loss = 0.9618 | mean accuracy = 0.7659\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.5586 | mean accuracy = 0.8458\n",
            "[valid] Epoch 4 mean loss = 0.9206 | mean accuracy = 0.7994\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.4532 | mean accuracy = 0.8781\n",
            "[valid] Epoch 5 mean loss = 0.8885 | mean accuracy = 0.7961\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.3454 | mean accuracy = 0.9037\n",
            "[valid] Epoch 6 mean loss = 0.8762 | mean accuracy = 0.7932\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.2621 | mean accuracy = 0.9243\n",
            "[valid] Epoch 7 mean loss = 0.8734 | mean accuracy = 0.7903\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1783 | mean accuracy = 0.9545\n",
            "[valid] Epoch 8 mean loss = 0.9195 | mean accuracy = 0.7853\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1481 | mean accuracy = 0.9635\n",
            "[valid] Epoch 9 mean loss = 1.0403 | mean accuracy = 0.7852\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.1256 | mean accuracy = 0.9727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:21:00,452] Trial 17 finished with value: 1.0826634019613266 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0016596900409684482, 'batch_size': 32}. Best is trial 16 with value: 0.7878151386976242.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 1.1155 | mean accuracy = 0.7907\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=64, learning_rate=0.0008725106985317709, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2408 | mean accuracy = 0.2203\n",
            "[valid] Epoch 1 mean loss = 2.2176 | mean accuracy = 0.3454\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 1.9905 | mean accuracy = 0.7824\n",
            "[valid] Epoch 2 mean loss = 1.8340 | mean accuracy = 0.7800\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.1241 | mean accuracy = 0.8156\n",
            "[valid] Epoch 3 mean loss = 1.1543 | mean accuracy = 0.7798\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.7228 | mean accuracy = 0.8157\n",
            "[valid] Epoch 4 mean loss = 1.0644 | mean accuracy = 0.8007\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.6386 | mean accuracy = 0.8304\n",
            "[valid] Epoch 5 mean loss = 1.0264 | mean accuracy = 0.8003\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.5774 | mean accuracy = 0.8312\n",
            "[valid] Epoch 6 mean loss = 1.0021 | mean accuracy = 0.7971\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.5232 | mean accuracy = 0.8580\n",
            "[valid] Epoch 7 mean loss = 0.9913 | mean accuracy = 0.7915\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.4669 | mean accuracy = 0.8734\n",
            "[valid] Epoch 8 mean loss = 0.9909 | mean accuracy = 0.7765\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:21:01,484] Trial 18 finished with value: 0.8394912332296371 and parameters: {'embedding_size': 64, 'hidden_size': 64, 'learning_rate': 0.0008725106985317709, 'batch_size': 32}. Best is trial 16 with value: 0.7878151386976242.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] Epoch 9 mean loss = 0.4058 | mean accuracy = 0.8797\n",
            "[valid] Epoch 9 mean loss = 0.9881 | mean accuracy = 0.7700\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.3469 | mean accuracy = 0.8934\n",
            "[valid] Epoch 10 mean loss = 1.0057 | mean accuracy = 0.7635\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=256, learning_rate=0.0002878359641906546, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 2.2489 | mean accuracy = 0.4788\n",
            "[valid] Epoch 1 mean loss = 2.2234 | mean accuracy = 0.6789\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 2.0642 | mean accuracy = 0.7972\n",
            "[valid] Epoch 2 mean loss = 1.9284 | mean accuracy = 0.7855\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 1.2904 | mean accuracy = 0.8248\n",
            "[valid] Epoch 3 mean loss = 1.2705 | mean accuracy = 0.7847\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.8934 | mean accuracy = 0.8257\n",
            "[valid] Epoch 4 mean loss = 1.1347 | mean accuracy = 0.8046\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.7790 | mean accuracy = 0.8364\n",
            "[valid] Epoch 5 mean loss = 1.0763 | mean accuracy = 0.8048\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.7036 | mean accuracy = 0.8362\n",
            "[valid] Epoch 6 mean loss = 1.0426 | mean accuracy = 0.8048\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.6543 | mean accuracy = 0.8411\n",
            "[valid] Epoch 7 mean loss = 1.0169 | mean accuracy = 0.8050\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.6066 | mean accuracy = 0.8527\n",
            "[valid] Epoch 8 mean loss = 0.9940 | mean accuracy = 0.8066\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.5656 | mean accuracy = 0.8523\n",
            "[valid] Epoch 9 mean loss = 0.9847 | mean accuracy = 0.7963\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.5227 | mean accuracy = 0.8627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:21:02,922] Trial 19 finished with value: 0.7641179263591766 and parameters: {'embedding_size': 64, 'hidden_size': 256, 'learning_rate': 0.0002878359641906546, 'batch_size': 32}. Best is trial 19 with value: 0.7641179263591766.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.9740 | mean accuracy = 0.7951\n",
            "\n",
            "Best configuration:\n",
            "{'embedding_size': 64, 'hidden_size': 256, 'learning_rate': 0.0002878359641906546, 'batch_size': 32}\n",
            "Best validation loss: 0.7641179263591766\n",
            "\n",
            "Time taken for small dataset: 22.12 seconds\n",
            "Estimated time for full dataset: 0.86 hours\n"
          ]
        }
      ],
      "source": [
        "#Optuna\n",
        "import optuna\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "\n",
        "# Subset the dataset for quicker testing\n",
        "subset_size = 100  # Adjust this to your desired small dataset size\n",
        "small_trainset = deepcopy(trainset)\n",
        "small_trainset.Xtokens = trainset.Xtokens[:subset_size]\n",
        "small_trainset.Ytokens = trainset.Ytokens[:subset_size]\n",
        "\n",
        "small_validset = deepcopy(validset)\n",
        "small_validset.Xtokens = validset.Xtokens[:subset_size]\n",
        "small_validset.Ytokens = validset.Ytokens[:subset_size]\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters using Optuna\n",
        "    embedding_size = trial.suggest_categorical(\"embedding_size\", [32, 64, 128])\n",
        "    hidden_size = trial.suggest_categorical(\"hidden_size\", [64, 128, 256])\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "\n",
        "    print(f\"\\nTesting configuration: embedding_size={embedding_size}, hidden_size={hidden_size}, \"\n",
        "          f\"learning_rate={learning_rate}, batch_size={batch_size}\")\n",
        "\n",
        "    # Create a new model\n",
        "    tagger = NERtagger(small_trainset, embedding_size, hidden_size, device='cuda')\n",
        "\n",
        "    # Train the model with the suggested hyperparameters\n",
        "    tagger.train_model(\n",
        "        traingenerator=small_trainset,\n",
        "        validgenerator=small_validset,\n",
        "        epochs=10,  # Reduced for quicker testing\n",
        "        batch_size=batch_size,\n",
        "        device='cuda',\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    # Validate the model and retrieve metrics\n",
        "    valid_loss, valid_accuracy = tagger.validate(small_validset, batch_size, device='cuda')\n",
        "\n",
        "    # Return validation loss as the objective to minimize\n",
        "    return valid_loss\n",
        "\n",
        "# Measure time for the optimization process\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction=\"minimize\")  # Minimize the validation loss\n",
        "study.optimize(objective, n_trials=20)  # Set number of trials\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Extrapolate based on the size of the dataset\n",
        "train_size_ratio = len(trainset.Xtokens) / len(small_trainset.Xtokens)\n",
        "total_time_estimate = elapsed_time * train_size_ratio\n",
        "\n",
        "# Best result\n",
        "best_result = study.best_params\n",
        "best_loss = study.best_value\n",
        "print(\"\\nBest configuration:\")\n",
        "print(best_result)\n",
        "print(f\"Best validation loss: {best_loss}\")\n",
        "print(f\"\\nTime taken for small dataset: {elapsed_time:.2f} seconds\")\n",
        "print(f\"Estimated time for full dataset: {total_time_estimate / 3600:.2f} hours\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYbXHpyZM7o7",
        "outputId": "15072a52-23ef-49ff-dcb8-7df5d41d9d0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:21:16,237] A new study created in memory with name: no-name-74c36813-6f9f-4337-8b3f-d622490fb0d4\n",
            "<ipython-input-17-c298c45a410c>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=128, learning_rate=0.0060505333502602655, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.2839 | mean accuracy = 0.9166\n",
            "[valid] Epoch 1 mean loss = 0.2285 | mean accuracy = 0.9303\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1050 | mean accuracy = 0.9678\n",
            "[valid] Epoch 2 mean loss = 0.2113 | mean accuracy = 0.9464\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.1044 | mean accuracy = 0.9715\n",
            "[valid] Epoch 3 mean loss = 0.3355 | mean accuracy = 0.9073\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0753 | mean accuracy = 0.9792\n",
            "[valid] Epoch 4 mean loss = 0.3110 | mean accuracy = 0.9222\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0579 | mean accuracy = 0.9846\n",
            "[valid] Epoch 5 mean loss = 0.3496 | mean accuracy = 0.9238\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0464 | mean accuracy = 0.9878\n",
            "[valid] Epoch 6 mean loss = 0.3535 | mean accuracy = 0.9308\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0422 | mean accuracy = 0.9892\n",
            "[valid] Epoch 7 mean loss = 0.3776 | mean accuracy = 0.9373\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0389 | mean accuracy = 0.9897\n",
            "[valid] Epoch 8 mean loss = 0.3690 | mean accuracy = 0.9372\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0345 | mean accuracy = 0.9912\n",
            "[valid] Epoch 9 mean loss = 0.3760 | mean accuracy = 0.9429\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0323 | mean accuracy = 0.9918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:27:59,652] Trial 0 finished with value: 0.42292219349274446 and parameters: {'embedding_size': 128, 'hidden_size': 128, 'learning_rate': 0.0060505333502602655, 'batch_size': 16}. Best is trial 0 with value: 0.42292219349274446.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.4216 | mean accuracy = 0.9398\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=128, learning_rate=0.00516785550973882, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.3524 | mean accuracy = 0.8949\n",
            "[valid] Epoch 1 mean loss = 0.2529 | mean accuracy = 0.9222\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1044 | mean accuracy = 0.9671\n",
            "[valid] Epoch 2 mean loss = 0.2062 | mean accuracy = 0.9430\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.0225 | mean accuracy = 0.9935\n",
            "[valid] Epoch 3 mean loss = 0.2409 | mean accuracy = 0.9484\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0259 | mean accuracy = 0.9921\n",
            "[valid] Epoch 4 mean loss = 0.2815 | mean accuracy = 0.9443\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0749 | mean accuracy = 0.9797\n",
            "[valid] Epoch 5 mean loss = 0.3596 | mean accuracy = 0.9232\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0530 | mean accuracy = 0.9851\n",
            "[valid] Epoch 6 mean loss = 0.3535 | mean accuracy = 0.9243\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0404 | mean accuracy = 0.9891\n",
            "[valid] Epoch 7 mean loss = 0.3402 | mean accuracy = 0.9314\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0338 | mean accuracy = 0.9908\n",
            "[valid] Epoch 8 mean loss = 0.4146 | mean accuracy = 0.9398\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0284 | mean accuracy = 0.9925\n",
            "[valid] Epoch 9 mean loss = 0.4792 | mean accuracy = 0.9453\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0277 | mean accuracy = 0.9929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:33:06,467] Trial 1 finished with value: 0.5394770292674794 and parameters: {'embedding_size': 128, 'hidden_size': 128, 'learning_rate': 0.00516785550973882, 'batch_size': 32}. Best is trial 0 with value: 0.42292219349274446.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.5359 | mean accuracy = 0.9460\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0023323062867411665, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.6980 | mean accuracy = 0.8030\n",
            "[valid] Epoch 1 mean loss = 0.5021 | mean accuracy = 0.8395\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.2856 | mean accuracy = 0.9107\n",
            "[valid] Epoch 2 mean loss = 0.2796 | mean accuracy = 0.9060\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.1274 | mean accuracy = 0.9605\n",
            "[valid] Epoch 3 mean loss = 0.2044 | mean accuracy = 0.9327\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0501 | mean accuracy = 0.9853\n",
            "[valid] Epoch 4 mean loss = 0.1895 | mean accuracy = 0.9414\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0576 | mean accuracy = 0.9819\n",
            "[valid] Epoch 5 mean loss = 0.2011 | mean accuracy = 0.9434\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0305 | mean accuracy = 0.9907\n",
            "[valid] Epoch 6 mean loss = 0.1945 | mean accuracy = 0.9471\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0186 | mean accuracy = 0.9941\n",
            "[valid] Epoch 7 mean loss = 0.2117 | mean accuracy = 0.9470\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0131 | mean accuracy = 0.9958\n",
            "[valid] Epoch 8 mean loss = 0.2258 | mean accuracy = 0.9481\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0106 | mean accuracy = 0.9968\n",
            "[valid] Epoch 9 mean loss = 0.2218 | mean accuracy = 0.9539\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0084 | mean accuracy = 0.9975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:37:32,113] Trial 2 finished with value: 0.28188638622854273 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0023323062867411665, 'batch_size': 64}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2789 | mean accuracy = 0.9493\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=256, learning_rate=0.00012812756195067034, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.8857 | mean accuracy = 0.7730\n",
            "[valid] Epoch 1 mean loss = 0.7721 | mean accuracy = 0.7981\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.5589 | mean accuracy = 0.8367\n",
            "[valid] Epoch 2 mean loss = 0.5750 | mean accuracy = 0.8261\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3922 | mean accuracy = 0.8829\n",
            "[valid] Epoch 3 mean loss = 0.4638 | mean accuracy = 0.8528\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.2852 | mean accuracy = 0.9119\n",
            "[valid] Epoch 4 mean loss = 0.4107 | mean accuracy = 0.8631\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.2103 | mean accuracy = 0.9341\n",
            "[valid] Epoch 5 mean loss = 0.4031 | mean accuracy = 0.8642\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.1532 | mean accuracy = 0.9526\n",
            "[valid] Epoch 6 mean loss = 0.3997 | mean accuracy = 0.8704\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1086 | mean accuracy = 0.9674\n",
            "[valid] Epoch 7 mean loss = 0.4188 | mean accuracy = 0.8748\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0734 | mean accuracy = 0.9787\n",
            "[valid] Epoch 8 mean loss = 0.4374 | mean accuracy = 0.8790\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0473 | mean accuracy = 0.9865\n",
            "[valid] Epoch 9 mean loss = 0.4585 | mean accuracy = 0.8805\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0295 | mean accuracy = 0.9922\n",
            "[valid] Epoch 10 mean loss = 0.4831 | mean accuracy = 0.8833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:44:41,954] Trial 3 finished with value: 0.483205793443702 and parameters: {'embedding_size': 64, 'hidden_size': 256, 'learning_rate': 0.00012812756195067034, 'batch_size': 16}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=64, learning_rate=0.0024162771804004833, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.4731 | mean accuracy = 0.8593\n",
            "[valid] Epoch 1 mean loss = 0.3553 | mean accuracy = 0.8878\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1759 | mean accuracy = 0.9455\n",
            "[valid] Epoch 2 mean loss = 0.2221 | mean accuracy = 0.9322\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.1005 | mean accuracy = 0.9684\n",
            "[valid] Epoch 3 mean loss = 0.2494 | mean accuracy = 0.9349\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0480 | mean accuracy = 0.9852\n",
            "[valid] Epoch 4 mean loss = 0.2482 | mean accuracy = 0.9433\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0253 | mean accuracy = 0.9922\n",
            "[valid] Epoch 5 mean loss = 0.2700 | mean accuracy = 0.9504\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0149 | mean accuracy = 0.9954\n",
            "[valid] Epoch 6 mean loss = 0.2416 | mean accuracy = 0.9487\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0108 | mean accuracy = 0.9967\n",
            "[valid] Epoch 7 mean loss = 0.3403 | mean accuracy = 0.9512\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0078 | mean accuracy = 0.9975\n",
            "[valid] Epoch 8 mean loss = 0.3424 | mean accuracy = 0.9541\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0062 | mean accuracy = 0.9980\n",
            "[valid] Epoch 9 mean loss = 0.4224 | mean accuracy = 0.9528\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0054 | mean accuracy = 0.9982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:50:25,836] Trial 4 finished with value: 0.4450937364321469 and parameters: {'embedding_size': 64, 'hidden_size': 64, 'learning_rate': 0.0024162771804004833, 'batch_size': 16}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.4415 | mean accuracy = 0.9522\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=64, learning_rate=0.0014274728479534019, batch_size=16\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.4912 | mean accuracy = 0.8579\n",
            "[valid] Epoch 1 mean loss = 0.3528 | mean accuracy = 0.8959\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1733 | mean accuracy = 0.9468\n",
            "[valid] Epoch 2 mean loss = 0.2726 | mean accuracy = 0.9070\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.0939 | mean accuracy = 0.9712\n",
            "[valid] Epoch 3 mean loss = 0.3535 | mean accuracy = 0.8947\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0375 | mean accuracy = 0.9881\n",
            "[valid] Epoch 4 mean loss = 0.5003 | mean accuracy = 0.8959\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0179 | mean accuracy = 0.9947\n",
            "[valid] Epoch 5 mean loss = 0.5540 | mean accuracy = 0.8999\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0096 | mean accuracy = 0.9972\n",
            "[valid] Epoch 6 mean loss = 0.6006 | mean accuracy = 0.9023\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0071 | mean accuracy = 0.9978\n",
            "[valid] Epoch 7 mean loss = 0.5949 | mean accuracy = 0.9024\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0050 | mean accuracy = 0.9984\n",
            "[valid] Epoch 8 mean loss = 0.7172 | mean accuracy = 0.9011\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0037 | mean accuracy = 0.9988\n",
            "[valid] Epoch 9 mean loss = 0.7756 | mean accuracy = 0.9057\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0022 | mean accuracy = 0.9994\n",
            "[valid] Epoch 10 mean loss = 1.0438 | mean accuracy = 0.8972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 19:56:54,095] Trial 5 finished with value: 1.0460843174334835 and parameters: {'embedding_size': 128, 'hidden_size': 64, 'learning_rate': 0.0014274728479534019, 'batch_size': 16}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0005015110812981718, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.9971 | mean accuracy = 0.7516\n",
            "[valid] Epoch 1 mean loss = 0.8089 | mean accuracy = 0.7939\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.5714 | mean accuracy = 0.8281\n",
            "[valid] Epoch 2 mean loss = 0.5209 | mean accuracy = 0.8453\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3630 | mean accuracy = 0.8880\n",
            "[valid] Epoch 3 mean loss = 0.3891 | mean accuracy = 0.8779\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.2465 | mean accuracy = 0.9232\n",
            "[valid] Epoch 4 mean loss = 0.3030 | mean accuracy = 0.9015\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1667 | mean accuracy = 0.9471\n",
            "[valid] Epoch 5 mean loss = 0.2900 | mean accuracy = 0.9016\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0861 | mean accuracy = 0.9738\n",
            "[valid] Epoch 6 mean loss = 0.2467 | mean accuracy = 0.9191\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0392 | mean accuracy = 0.9885\n",
            "[valid] Epoch 7 mean loss = 0.2322 | mean accuracy = 0.9303\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0170 | mean accuracy = 0.9955\n",
            "[valid] Epoch 8 mean loss = 0.2631 | mean accuracy = 0.9291\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0082 | mean accuracy = 0.9978\n",
            "[valid] Epoch 9 mean loss = 0.2382 | mean accuracy = 0.9416\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0047 | mean accuracy = 0.9987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:01:20,297] Trial 6 finished with value: 0.2900930984931834 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0005015110812981718, 'batch_size': 64}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2733 | mean accuracy = 0.9372\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.002832076974710779, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.5185 | mean accuracy = 0.8487\n",
            "[valid] Epoch 1 mean loss = 0.4105 | mean accuracy = 0.8600\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1980 | mean accuracy = 0.9383\n",
            "[valid] Epoch 2 mean loss = 0.2619 | mean accuracy = 0.9094\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.0778 | mean accuracy = 0.9765\n",
            "[valid] Epoch 3 mean loss = 0.2353 | mean accuracy = 0.9201\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0297 | mean accuracy = 0.9914\n",
            "[valid] Epoch 4 mean loss = 0.2085 | mean accuracy = 0.9374\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.0593 | mean accuracy = 0.9816\n",
            "[valid] Epoch 5 mean loss = 0.5088 | mean accuracy = 0.8831\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0345 | mean accuracy = 0.9896\n",
            "[valid] Epoch 6 mean loss = 0.6396 | mean accuracy = 0.8888\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0232 | mean accuracy = 0.9926\n",
            "[valid] Epoch 7 mean loss = 0.7001 | mean accuracy = 0.8909\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0172 | mean accuracy = 0.9947\n",
            "[valid] Epoch 8 mean loss = 0.7772 | mean accuracy = 0.8891\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0125 | mean accuracy = 0.9961\n",
            "[valid] Epoch 9 mean loss = 0.5815 | mean accuracy = 0.9039\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0112 | mean accuracy = 0.9967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:05:47,054] Trial 7 finished with value: 0.607401345874749 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.002832076974710779, 'batch_size': 32}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.5954 | mean accuracy = 0.9107\n",
            "\n",
            "Testing configuration: embedding_size=128, hidden_size=128, learning_rate=0.00972651280210201, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.3759 | mean accuracy = 0.8899\n",
            "[valid] Epoch 1 mean loss = 0.2522 | mean accuracy = 0.9211\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.1112 | mean accuracy = 0.9657\n",
            "[valid] Epoch 2 mean loss = 0.2439 | mean accuracy = 0.9293\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.0358 | mean accuracy = 0.9894\n",
            "[valid] Epoch 3 mean loss = 0.2229 | mean accuracy = 0.9443\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.0453 | mean accuracy = 0.9870\n",
            "[valid] Epoch 4 mean loss = 0.2698 | mean accuracy = 0.9368\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1062 | mean accuracy = 0.9759\n",
            "[valid] Epoch 5 mean loss = 0.4487 | mean accuracy = 0.8908\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.1002 | mean accuracy = 0.9767\n",
            "[valid] Epoch 6 mean loss = 0.3873 | mean accuracy = 0.8979\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0921 | mean accuracy = 0.9788\n",
            "[valid] Epoch 7 mean loss = 0.5052 | mean accuracy = 0.8888\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0889 | mean accuracy = 0.9792\n",
            "[valid] Epoch 8 mean loss = 0.4528 | mean accuracy = 0.8954\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0822 | mean accuracy = 0.9811\n",
            "[valid] Epoch 9 mean loss = 0.4034 | mean accuracy = 0.9151\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0787 | mean accuracy = 0.9827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:10:53,133] Trial 8 finished with value: 0.4960346952372906 and parameters: {'embedding_size': 128, 'hidden_size': 128, 'learning_rate': 0.00972651280210201, 'batch_size': 64}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.4906 | mean accuracy = 0.8952\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=256, learning_rate=0.0009029264195416358, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.7244 | mean accuracy = 0.7933\n",
            "[valid] Epoch 1 mean loss = 0.6281 | mean accuracy = 0.8090\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.4549 | mean accuracy = 0.8605\n",
            "[valid] Epoch 2 mean loss = 0.4670 | mean accuracy = 0.8439\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3086 | mean accuracy = 0.9035\n",
            "[valid] Epoch 3 mean loss = 0.3455 | mean accuracy = 0.8868\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.2085 | mean accuracy = 0.9346\n",
            "[valid] Epoch 4 mean loss = 0.2798 | mean accuracy = 0.9062\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1503 | mean accuracy = 0.9521\n",
            "[valid] Epoch 5 mean loss = 0.2805 | mean accuracy = 0.9054\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0745 | mean accuracy = 0.9767\n",
            "[valid] Epoch 6 mean loss = 0.2732 | mean accuracy = 0.9177\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0320 | mean accuracy = 0.9901\n",
            "[valid] Epoch 7 mean loss = 0.3252 | mean accuracy = 0.9140\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0157 | mean accuracy = 0.9951\n",
            "[valid] Epoch 8 mean loss = 0.3356 | mean accuracy = 0.9127\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0101 | mean accuracy = 0.9971\n",
            "[valid] Epoch 9 mean loss = 0.3664 | mean accuracy = 0.9234\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0071 | mean accuracy = 0.9979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:16:10,532] Trial 9 finished with value: 0.33900219822923344 and parameters: {'embedding_size': 32, 'hidden_size': 256, 'learning_rate': 0.0009029264195416358, 'batch_size': 32}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.3370 | mean accuracy = 0.9217\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=64, learning_rate=0.0003414176792983604, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.2129 | mean accuracy = 0.7119\n",
            "[valid] Epoch 1 mean loss = 0.9519 | mean accuracy = 0.7706\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.7796 | mean accuracy = 0.7770\n",
            "[valid] Epoch 2 mean loss = 0.7475 | mean accuracy = 0.7980\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6021 | mean accuracy = 0.8189\n",
            "[valid] Epoch 3 mean loss = 0.6002 | mean accuracy = 0.8241\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.4584 | mean accuracy = 0.8588\n",
            "[valid] Epoch 4 mean loss = 0.4886 | mean accuracy = 0.8508\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3281 | mean accuracy = 0.8976\n",
            "[valid] Epoch 5 mean loss = 0.4221 | mean accuracy = 0.8608\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2357 | mean accuracy = 0.9260\n",
            "[valid] Epoch 6 mean loss = 0.3696 | mean accuracy = 0.8720\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1762 | mean accuracy = 0.9454\n",
            "[valid] Epoch 7 mean loss = 0.3447 | mean accuracy = 0.8796\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1337 | mean accuracy = 0.9591\n",
            "[valid] Epoch 8 mean loss = 0.3258 | mean accuracy = 0.8854\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1013 | mean accuracy = 0.9697\n",
            "[valid] Epoch 9 mean loss = 0.3303 | mean accuracy = 0.8874\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0752 | mean accuracy = 0.9777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:20:23,964] Trial 10 finished with value: 0.3406760724736195 and parameters: {'embedding_size': 32, 'hidden_size': 64, 'learning_rate': 0.0003414176792983604, 'batch_size': 64}. Best is trial 2 with value: 0.28188638622854273.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.3399 | mean accuracy = 0.8905\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0005420612939490512, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.9773 | mean accuracy = 0.7453\n",
            "[valid] Epoch 1 mean loss = 0.7815 | mean accuracy = 0.7941\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.5558 | mean accuracy = 0.8354\n",
            "[valid] Epoch 2 mean loss = 0.5106 | mean accuracy = 0.8431\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3547 | mean accuracy = 0.8926\n",
            "[valid] Epoch 3 mean loss = 0.3815 | mean accuracy = 0.8808\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.2387 | mean accuracy = 0.9261\n",
            "[valid] Epoch 4 mean loss = 0.2968 | mean accuracy = 0.9081\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1592 | mean accuracy = 0.9498\n",
            "[valid] Epoch 5 mean loss = 0.2432 | mean accuracy = 0.9224\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0789 | mean accuracy = 0.9759\n",
            "[valid] Epoch 6 mean loss = 0.2081 | mean accuracy = 0.9376\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0348 | mean accuracy = 0.9898\n",
            "[valid] Epoch 7 mean loss = 0.2066 | mean accuracy = 0.9426\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0151 | mean accuracy = 0.9958\n",
            "[valid] Epoch 8 mean loss = 0.2165 | mean accuracy = 0.9467\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0073 | mean accuracy = 0.9981\n",
            "[valid] Epoch 9 mean loss = 0.2390 | mean accuracy = 0.9468\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0050 | mean accuracy = 0.9986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:24:51,437] Trial 11 finished with value: 0.26232793138307686 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0005420612939490512, 'batch_size': 64}. Best is trial 11 with value: 0.26232793138307686.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2539 | mean accuracy = 0.9450\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0004520724638002848, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.0100 | mean accuracy = 0.7579\n",
            "[valid] Epoch 1 mean loss = 0.8009 | mean accuracy = 0.7845\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.5925 | mean accuracy = 0.8241\n",
            "[valid] Epoch 2 mean loss = 0.5272 | mean accuracy = 0.8427\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3861 | mean accuracy = 0.8810\n",
            "[valid] Epoch 3 mean loss = 0.4046 | mean accuracy = 0.8739\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.2696 | mean accuracy = 0.9164\n",
            "[valid] Epoch 4 mean loss = 0.3262 | mean accuracy = 0.8953\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1853 | mean accuracy = 0.9416\n",
            "[valid] Epoch 5 mean loss = 0.2599 | mean accuracy = 0.9181\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0988 | mean accuracy = 0.9697\n",
            "[valid] Epoch 6 mean loss = 0.2456 | mean accuracy = 0.9240\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0475 | mean accuracy = 0.9864\n",
            "[valid] Epoch 7 mean loss = 0.2722 | mean accuracy = 0.9259\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0211 | mean accuracy = 0.9941\n",
            "[valid] Epoch 8 mean loss = 0.3090 | mean accuracy = 0.9255\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0103 | mean accuracy = 0.9973\n",
            "[valid] Epoch 9 mean loss = 0.3399 | mean accuracy = 0.9298\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0058 | mean accuracy = 0.9986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:29:17,396] Trial 12 finished with value: 0.3921160674562641 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0004520724638002848, 'batch_size': 64}. Best is trial 11 with value: 0.26232793138307686.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.3834 | mean accuracy = 0.9304\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0001847078780156269, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.2486 | mean accuracy = 0.7143\n",
            "[valid] Epoch 1 mean loss = 0.9922 | mean accuracy = 0.7724\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.7919 | mean accuracy = 0.7760\n",
            "[valid] Epoch 2 mean loss = 0.7203 | mean accuracy = 0.7946\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.5853 | mean accuracy = 0.8252\n",
            "[valid] Epoch 3 mean loss = 0.5472 | mean accuracy = 0.8361\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.4430 | mean accuracy = 0.8662\n",
            "[valid] Epoch 4 mean loss = 0.4386 | mean accuracy = 0.8642\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3259 | mean accuracy = 0.8997\n",
            "[valid] Epoch 5 mean loss = 0.3489 | mean accuracy = 0.8861\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2295 | mean accuracy = 0.9290\n",
            "[valid] Epoch 6 mean loss = 0.2825 | mean accuracy = 0.9056\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1644 | mean accuracy = 0.9500\n",
            "[valid] Epoch 7 mean loss = 0.2455 | mean accuracy = 0.9194\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1170 | mean accuracy = 0.9649\n",
            "[valid] Epoch 8 mean loss = 0.2250 | mean accuracy = 0.9290\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0809 | mean accuracy = 0.9767\n",
            "[valid] Epoch 9 mean loss = 0.2174 | mean accuracy = 0.9331\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0535 | mean accuracy = 0.9850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:33:43,436] Trial 13 finished with value: 0.2262512398701088 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0001847078780156269, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2172 | mean accuracy = 0.9358\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=256, learning_rate=0.00010604025377179749, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.2693 | mean accuracy = 0.7355\n",
            "[valid] Epoch 1 mean loss = 1.0352 | mean accuracy = 0.7696\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.8221 | mean accuracy = 0.7747\n",
            "[valid] Epoch 2 mean loss = 0.7666 | mean accuracy = 0.7984\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6246 | mean accuracy = 0.8187\n",
            "[valid] Epoch 3 mean loss = 0.6159 | mean accuracy = 0.8189\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.4989 | mean accuracy = 0.8528\n",
            "[valid] Epoch 4 mean loss = 0.5325 | mean accuracy = 0.8395\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3834 | mean accuracy = 0.8841\n",
            "[valid] Epoch 5 mean loss = 0.4402 | mean accuracy = 0.8630\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2909 | mean accuracy = 0.9099\n",
            "[valid] Epoch 6 mean loss = 0.3743 | mean accuracy = 0.8834\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.2218 | mean accuracy = 0.9309\n",
            "[valid] Epoch 7 mean loss = 0.3263 | mean accuracy = 0.8981\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1698 | mean accuracy = 0.9472\n",
            "[valid] Epoch 8 mean loss = 0.3018 | mean accuracy = 0.9077\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1276 | mean accuracy = 0.9608\n",
            "[valid] Epoch 9 mean loss = 0.2880 | mean accuracy = 0.9163\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0938 | mean accuracy = 0.9720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:39:14,181] Trial 14 finished with value: 0.29498225684259455 and parameters: {'embedding_size': 64, 'hidden_size': 256, 'learning_rate': 0.00010604025377179749, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2879 | mean accuracy = 0.9193\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.00021755877534950923, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.1855 | mean accuracy = 0.7313\n",
            "[valid] Epoch 1 mean loss = 0.9664 | mean accuracy = 0.7712\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.7370 | mean accuracy = 0.7941\n",
            "[valid] Epoch 2 mean loss = 0.6937 | mean accuracy = 0.8101\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.5350 | mean accuracy = 0.8440\n",
            "[valid] Epoch 3 mean loss = 0.5499 | mean accuracy = 0.8379\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.4068 | mean accuracy = 0.8762\n",
            "[valid] Epoch 4 mean loss = 0.4490 | mean accuracy = 0.8657\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.2975 | mean accuracy = 0.9075\n",
            "[valid] Epoch 5 mean loss = 0.3660 | mean accuracy = 0.8751\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2012 | mean accuracy = 0.9372\n",
            "[valid] Epoch 6 mean loss = 0.3105 | mean accuracy = 0.8906\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1371 | mean accuracy = 0.9585\n",
            "[valid] Epoch 7 mean loss = 0.2782 | mean accuracy = 0.8978\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0908 | mean accuracy = 0.9733\n",
            "[valid] Epoch 8 mean loss = 0.2746 | mean accuracy = 0.9034\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0579 | mean accuracy = 0.9838\n",
            "[valid] Epoch 9 mean loss = 0.2788 | mean accuracy = 0.9053\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0356 | mean accuracy = 0.9904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:43:40,715] Trial 15 finished with value: 0.2946326095683902 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.00021755877534950923, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2938 | mean accuracy = 0.9080\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=128, learning_rate=0.0002080928795447582, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.2306 | mean accuracy = 0.6846\n",
            "[valid] Epoch 1 mean loss = 1.0164 | mean accuracy = 0.7693\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.8195 | mean accuracy = 0.7735\n",
            "[valid] Epoch 2 mean loss = 0.7823 | mean accuracy = 0.7791\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.6459 | mean accuracy = 0.8068\n",
            "[valid] Epoch 3 mean loss = 0.6350 | mean accuracy = 0.8148\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.5155 | mean accuracy = 0.8442\n",
            "[valid] Epoch 4 mean loss = 0.5447 | mean accuracy = 0.8373\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3970 | mean accuracy = 0.8771\n",
            "[valid] Epoch 5 mean loss = 0.4444 | mean accuracy = 0.8621\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.3000 | mean accuracy = 0.9058\n",
            "[valid] Epoch 6 mean loss = 0.3652 | mean accuracy = 0.8873\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.2329 | mean accuracy = 0.9270\n",
            "[valid] Epoch 7 mean loss = 0.3157 | mean accuracy = 0.8999\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1829 | mean accuracy = 0.9427\n",
            "[valid] Epoch 8 mean loss = 0.2880 | mean accuracy = 0.9073\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.1426 | mean accuracy = 0.9557\n",
            "[valid] Epoch 9 mean loss = 0.2753 | mean accuracy = 0.9122\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.1095 | mean accuracy = 0.9667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:48:08,625] Trial 16 finished with value: 0.27874122501588333 and parameters: {'embedding_size': 32, 'hidden_size': 128, 'learning_rate': 0.0002080928795447582, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2687 | mean accuracy = 0.9145\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=128, learning_rate=0.0007070995565111161, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.9349 | mean accuracy = 0.7602\n",
            "[valid] Epoch 1 mean loss = 0.7191 | mean accuracy = 0.8010\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.5015 | mean accuracy = 0.8483\n",
            "[valid] Epoch 2 mean loss = 0.4650 | mean accuracy = 0.8537\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.3031 | mean accuracy = 0.9059\n",
            "[valid] Epoch 3 mean loss = 0.3429 | mean accuracy = 0.8898\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.1907 | mean accuracy = 0.9410\n",
            "[valid] Epoch 4 mean loss = 0.2719 | mean accuracy = 0.9137\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.1239 | mean accuracy = 0.9617\n",
            "[valid] Epoch 5 mean loss = 0.2484 | mean accuracy = 0.9254\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.0552 | mean accuracy = 0.9836\n",
            "[valid] Epoch 6 mean loss = 0.2294 | mean accuracy = 0.9380\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.0221 | mean accuracy = 0.9938\n",
            "[valid] Epoch 7 mean loss = 0.2361 | mean accuracy = 0.9423\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0100 | mean accuracy = 0.9971\n",
            "[valid] Epoch 8 mean loss = 0.2540 | mean accuracy = 0.9425\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0057 | mean accuracy = 0.9982\n",
            "[valid] Epoch 9 mean loss = 0.2706 | mean accuracy = 0.9468\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0043 | mean accuracy = 0.9988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:52:49,400] Trial 17 finished with value: 0.3016170789213741 and parameters: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0007070995565111161, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.2882 | mean accuracy = 0.9481\n",
            "\n",
            "Testing configuration: embedding_size=64, hidden_size=256, learning_rate=0.00020082829074530813, batch_size=64\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 1.1038 | mean accuracy = 0.7334\n",
            "[valid] Epoch 1 mean loss = 0.9120 | mean accuracy = 0.7764\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.6856 | mean accuracy = 0.8087\n",
            "[valid] Epoch 2 mean loss = 0.6244 | mean accuracy = 0.8172\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.4899 | mean accuracy = 0.8545\n",
            "[valid] Epoch 3 mean loss = 0.5036 | mean accuracy = 0.8461\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.3790 | mean accuracy = 0.8859\n",
            "[valid] Epoch 4 mean loss = 0.4234 | mean accuracy = 0.8693\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.2862 | mean accuracy = 0.9113\n",
            "[valid] Epoch 5 mean loss = 0.3625 | mean accuracy = 0.8760\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.1877 | mean accuracy = 0.9415\n",
            "[valid] Epoch 6 mean loss = 0.3014 | mean accuracy = 0.8950\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1189 | mean accuracy = 0.9636\n",
            "[valid] Epoch 7 mean loss = 0.2765 | mean accuracy = 0.9029\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.0702 | mean accuracy = 0.9793\n",
            "[valid] Epoch 8 mean loss = 0.2737 | mean accuracy = 0.9067\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0385 | mean accuracy = 0.9892\n",
            "[valid] Epoch 9 mean loss = 0.2943 | mean accuracy = 0.9076\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0199 | mean accuracy = 0.9948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 20:58:53,082] Trial 18 finished with value: 0.3206683176697469 and parameters: {'embedding_size': 64, 'hidden_size': 256, 'learning_rate': 0.00020082829074530813, 'batch_size': 64}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.3125 | mean accuracy = 0.9090\n",
            "\n",
            "Testing configuration: embedding_size=32, hidden_size=64, learning_rate=0.0003426719736850518, batch_size=32\n",
            "\n",
            "Epoch 1/10\n",
            "[train] Epoch 1 mean loss = 0.9998 | mean accuracy = 0.7547\n",
            "[valid] Epoch 1 mean loss = 0.8542 | mean accuracy = 0.7741\n",
            "\n",
            "Epoch 2/10\n",
            "[train] Epoch 2 mean loss = 0.7207 | mean accuracy = 0.7846\n",
            "[valid] Epoch 2 mean loss = 0.7050 | mean accuracy = 0.7970\n",
            "\n",
            "Epoch 3/10\n",
            "[train] Epoch 3 mean loss = 0.5636 | mean accuracy = 0.8268\n",
            "[valid] Epoch 3 mean loss = 0.6065 | mean accuracy = 0.8273\n",
            "\n",
            "Epoch 4/10\n",
            "[train] Epoch 4 mean loss = 0.4325 | mean accuracy = 0.8667\n",
            "[valid] Epoch 4 mean loss = 0.5376 | mean accuracy = 0.8520\n",
            "\n",
            "Epoch 5/10\n",
            "[train] Epoch 5 mean loss = 0.3163 | mean accuracy = 0.9010\n",
            "[valid] Epoch 5 mean loss = 0.4845 | mean accuracy = 0.8729\n",
            "\n",
            "Epoch 6/10\n",
            "[train] Epoch 6 mean loss = 0.2285 | mean accuracy = 0.9274\n",
            "[valid] Epoch 6 mean loss = 0.4476 | mean accuracy = 0.8947\n",
            "\n",
            "Epoch 7/10\n",
            "[train] Epoch 7 mean loss = 0.1714 | mean accuracy = 0.9459\n",
            "[valid] Epoch 7 mean loss = 0.4265 | mean accuracy = 0.9080\n",
            "\n",
            "Epoch 8/10\n",
            "[train] Epoch 8 mean loss = 0.1293 | mean accuracy = 0.9600\n",
            "[valid] Epoch 8 mean loss = 0.4197 | mean accuracy = 0.9152\n",
            "\n",
            "Epoch 9/10\n",
            "[train] Epoch 9 mean loss = 0.0970 | mean accuracy = 0.9704\n",
            "[valid] Epoch 9 mean loss = 0.4233 | mean accuracy = 0.9194\n",
            "\n",
            "Epoch 10/10\n",
            "[train] Epoch 10 mean loss = 0.0716 | mean accuracy = 0.9787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-20 21:03:17,825] Trial 19 finished with value: 0.4403449323247461 and parameters: {'embedding_size': 32, 'hidden_size': 64, 'learning_rate': 0.0003426719736850518, 'batch_size': 32}. Best is trial 13 with value: 0.2262512398701088.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[valid] Epoch 10 mean loss = 0.4331 | mean accuracy = 0.9226\n",
            "\n",
            "Best configuration:\n",
            "{'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0001847078780156269, 'batch_size': 64}\n",
            "Best validation loss: 0.2262512398701088\n",
            "\n",
            "Total time taken: 6121.59 seconds\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# Load the full dataset\n",
        "trainset = DataGenerator('eng.train')  # Full training dataset\n",
        "validset = DataGenerator('eng.testa', parentgenerator=trainset)  # Validation dataset\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters using Optuna\n",
        "    embedding_size = trial.suggest_categorical(\"embedding_size\", [32, 64, 128])\n",
        "    hidden_size = trial.suggest_categorical(\"hidden_size\", [64, 128, 256])\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "\n",
        "    print(f\"\\nTesting configuration: embedding_size={embedding_size}, hidden_size={hidden_size}, \"\n",
        "          f\"learning_rate={learning_rate}, batch_size={batch_size}\")\n",
        "\n",
        "    # Create a new model\n",
        "    tagger = NERtagger(trainset, embedding_size, hidden_size, device='cuda')\n",
        "\n",
        "    # Train the model with the suggested hyperparameters\n",
        "    tagger.train_model(\n",
        "        traingenerator=trainset,\n",
        "        validgenerator=validset,\n",
        "        epochs=10,  # Number of epochs\n",
        "        batch_size=batch_size,\n",
        "        device='cuda',\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    # Validate the model and retrieve metrics\n",
        "    valid_loss, valid_accuracy = tagger.validate(validset, batch_size, device='cuda')\n",
        "\n",
        "    # Return validation loss as the objective to minimize\n",
        "    return valid_loss\n",
        "\n",
        "# Measure time for the optimization process\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a study and optimize\n",
        "study = optuna.create_study(direction=\"minimize\")  # Minimize the validation loss\n",
        "study.optimize(objective, n_trials=20)  # Number of trials\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Best result\n",
        "best_result = study.best_params\n",
        "best_loss = study.best_value\n",
        "print(\"\\nBest configuration:\")\n",
        "print(best_result)\n",
        "print(f\"Best validation loss: {best_loss}\")\n",
        "print(f\"\\nTotal time taken: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c--xTLmT9zIc"
      },
      "source": [
        "# Improvements\n",
        "\n",
        "To improve the NER Tagger we firsly need to modify `vocabulary` function by adding there POS tag and Characters mapping, to add `read_conll_pos` function for POS tags, to add new function for caharcters extraction, a new `datagenerator` with pos_sym2idx, pos_idx2sym, char_sym2idx, char_idx2sym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o9g72DgTDfy"
      },
      "outputs": [],
      "source": [
        "# NEW VOCABULARY with pos_tag and char mapping\n",
        "def vocabulary(filename, vocab_type, padding='<pad>', unknown='<unk>'):\n",
        "    # vocab_type tells the type of vocabulary to create: 'input', 'output', 'pos', 'char'\n",
        "    # the optional flags indicate that a padding and an unknown token have to be added to the vocabulary\n",
        "    # if their value is not None\n",
        "\n",
        "    idx2sym = {}\n",
        "    sym2idx = {}\n",
        "\n",
        "    cur_idx = 0\n",
        "    # Add pad and unk tokens to the vocab if applicable\n",
        "    if padding:\n",
        "      idx2sym[cur_idx] = padding\n",
        "      sym2idx[padding] = cur_idx\n",
        "      cur_idx += 1\n",
        "    if unknown:\n",
        "      idx2sym[cur_idx] = unknown\n",
        "      sym2idx[unknown] = cur_idx\n",
        "      cur_idx += 1\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "\n",
        "        if not line or line.startswith('-DOCSTART-'):\n",
        "          continue  # Skip empty lines and metadata\n",
        "\n",
        "        parts = line.split()\n",
        "        if vocab_type == 'input':\n",
        "          token = parts[0]  # Token\n",
        "          if token not in sym2idx:\n",
        "            idx2sym[cur_idx] = token\n",
        "            sym2idx[token] = cur_idx\n",
        "            cur_idx += 1\n",
        "\n",
        "        elif vocab_type == 'output':\n",
        "          tag = parts[-1]  # NER tag\n",
        "          if tag not in sym2idx:\n",
        "            idx2sym[cur_idx] = tag\n",
        "            sym2idx[tag] = cur_idx\n",
        "            cur_idx += 1\n",
        "\n",
        "        elif vocab_type == 'pos':\n",
        "          pos_tag = parts[1]  # POS tag\n",
        "          if pos_tag not in sym2idx:\n",
        "            idx2sym[cur_idx] = pos_tag\n",
        "            sym2idx[pos_tag] = cur_idx\n",
        "            cur_idx += 1\n",
        "\n",
        "        elif vocab_type == 'char':\n",
        "          token = parts[0]  # Token\n",
        "          for char in token:  # Extract all characters from the token\n",
        "            if char not in sym2idx:\n",
        "              idx2sym[cur_idx] = char\n",
        "              sym2idx[char] = cur_idx\n",
        "              cur_idx += 1\n",
        "\n",
        "    return idx2sym, sym2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If548NpUW8ph"
      },
      "outputs": [],
      "source": [
        "# ADD read_conll function for POS tags\n",
        "def read_conll_pos(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (POS tags)\n",
        "    \"\"\"\n",
        "    #TODO\n",
        "    sentences = []\n",
        "    cur_sent = []\n",
        "\n",
        "    with open(conllfilename, 'r') as f:\n",
        "      for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "          if cur_sent:\n",
        "            sentences.append(cur_sent)\n",
        "            cur_sent = []\n",
        "        elif not line.startswith('-DOCSTART-'):\n",
        "        #else:\n",
        "          parts = line.split()\n",
        "          cur_sent.append(parts[1])   # POS tag\n",
        "\n",
        "    if cur_sent:\n",
        "      sentences.append(cur_sent)\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF3khMO4bMAY"
      },
      "outputs": [],
      "source": [
        "# NEW function to extract characters\n",
        "def extract_char_sequences(tokens):\n",
        "    char_sequences = []\n",
        "    for sentence in tokens:\n",
        "      char_sequences.append([[char for char in token] for token in sentence])\n",
        "    return char_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt3mKMlbcjc_",
        "outputId": "c9ce8ba9-e007-4267-aee8-df409419551e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n",
            "['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', 'JJ', 'NN', '.']\n",
            "[['E', 'U'], ['r', 'e', 'j', 'e', 'c', 't', 's'], ['G', 'e', 'r', 'm', 'a', 'n'], ['c', 'a', 'l', 'l'], ['t', 'o'], ['b', 'o', 'y', 'c', 'o', 't', 't'], ['B', 'r', 'i', 't', 'i', 's', 'h'], ['l', 'a', 'm', 'b'], ['.']]\n",
            "\n",
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.', '<pad>', '<pad>', '<pad>']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', '<pad>', '<pad>', '<pad>']\n",
            "['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', 'JJ', 'NN', '.', '<pad>', '<pad>', '<pad>']\n",
            "[['E', 'U', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['r', 'e', 'j', 'e', 'c', 't', 's', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['G', 'e', 'r', 'm', 'a', 'n', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['c', 'a', 'l', 'l', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['t', 'o', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['b', 'o', 'y', 'c', 'o', 't', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['B', 'r', 'i', 't', 'i', 's', 'h', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['l', 'a', 'm', 'b', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0]\n",
            "[2, 3, 4, 3, 3, 3, 4, 3, 3, 0, 0, 0]\n",
            "[2, 3, 4, 5, 6, 7, 4, 5, 8, 0, 0, 0]\n",
            "[[2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 5, 6, 5, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0], [10, 5, 4, 11, 12, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 12, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [8, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [16, 15, 17, 7, 15, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0], [18, 4, 19, 8, 19, 9, 20, 0, 0, 0, 0, 0, 0, 0, 0], [14, 12, 11, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.', '<pad>', '<pad>', '<pad>']\n",
            "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', '<pad>', '<pad>', '<pad>']\n",
            "['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', 'JJ', 'NN', '.', '<pad>', '<pad>', '<pad>']\n",
            "[['E', 'U', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['r', 'e', 'j', 'e', 'c', 't', 's', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['G', 'e', 'r', 'm', 'a', 'n', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['c', 'a', 'l', 'l', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['t', 'o', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['b', 'o', 'y', 'c', 'o', 't', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['B', 'r', 'i', 't', 'i', 's', 'h', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['l', 'a', 'm', 'b', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n"
          ]
        }
      ],
      "source": [
        "# Test on first sentence Pad sequences, Encode sequences and Decode sequences\n",
        "sample_tokens = tokens[0]\n",
        "sample_tags = tags[0]\n",
        "sample_pos = pos_tags[0]\n",
        "sample_chars = char_sequences[0]\n",
        "print(sample_tokens)\n",
        "print(sample_tags)\n",
        "print(sample_pos)\n",
        "print(sample_chars)\n",
        "print()\n",
        "\n",
        "# Pad sequences\n",
        "padded_tokens = pad_sequence(sample_tokens, pad_size=12, pad_token='<pad>')\n",
        "padded_tags = pad_sequence(sample_tags, pad_size=12, pad_token='<pad>')\n",
        "padded_pos = pad_sequence(sample_pos, pad_size=12, pad_token='<pad>')\n",
        "padded_chars = [pad_sequence(char_seq, pad_size=15, pad_token='<pad>') for char_seq in sample_chars]\n",
        "print(padded_tokens)\n",
        "print(padded_tags)\n",
        "print(padded_pos)\n",
        "print(padded_chars)\n",
        "print()\n",
        "\n",
        "# Encode sequences\n",
        "encoded_tokens = code_sequence(padded_tokens, input_sym2idx, unk_token='<unk>')\n",
        "encoded_tags = code_sequence(padded_tags, output_sym2idx, unk_token='<unk>')\n",
        "encoded_pos = code_sequence(padded_pos, pos_sym2idx, unk_token='<unk>')\n",
        "encoded_chars = [code_sequence(char_seq, char_sym2idx, unk_token='<unk>') for char_seq in padded_chars]\n",
        "print(encoded_tokens)\n",
        "print(encoded_tags)\n",
        "print(encoded_pos)\n",
        "print(encoded_chars)\n",
        "print()\n",
        "\n",
        "# Decode sequences\n",
        "decoded_tokens = decode_sequence(encoded_tokens, input_idx2sym)\n",
        "decoded_tags = decode_sequence(encoded_tags, output_idx2sym)\n",
        "decoded_pos = decode_sequence(encoded_pos, pos_idx2sym)\n",
        "decoded_chars = [decode_sequence(char_seq, char_idx2sym) for char_seq in encoded_chars]\n",
        "print(decoded_tokens)\n",
        "print(decoded_tags)\n",
        "print(decoded_pos)\n",
        "print(decoded_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWGAuUw7jaHo"
      },
      "outputs": [],
      "source": [
        "# NEW datagenerator with pos_sym2idx, pos_idx2sym, char_sym2idx, char_idx2sym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None:\n",
        "                  self.pad_token = parentgenerator.pad_token\n",
        "                  self.unk_token = parentgenerator.unk_token\n",
        "                  self.input_sym2idx = parentgenerator.input_sym2idx\n",
        "                  self.input_idx2sym = parentgenerator.input_idx2sym\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx\n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym\n",
        "                  self.pos_sym2idx = parentgenerator.pos_sym2idx\n",
        "                  self.pos_idx2sym = parentgenerator.pos_idx2sym\n",
        "                  self.char_sym2idx = parentgenerator.char_sym2idx\n",
        "                  self.char_idx2sym = parentgenerator.char_idx2sym\n",
        "              else:                           # Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  #TODO : Create 8 encoding maps from datafile\n",
        "                  self.input_idx2sym, self.input_sym2idx = vocabulary(conllfilename, vocab_type='input', padding=pad_token, unknown=unk_token)\n",
        "                  self.output_idx2sym, self.output_sym2idx = vocabulary(conllfilename, vocab_type='output', padding=pad_token, unknown=unk_token)\n",
        "                  self.pos_idx2sym, self.pos_sym2idx = vocabulary(conllfilename, vocab_type='pos', padding=pad_token, unknown=unk_token)\n",
        "                  self.char_idx2sym, self.char_sym2idx = vocabulary(conllfilename, vocab_type='char', padding=pad_token, unknown=unk_token)\n",
        "\n",
        "              #TODO : store the conll dataset with sentence structure (a list of lists of strings) in the following fields\n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename)\n",
        "              self.Xpos = read_conll_pos(conllfilename)\n",
        "              self.Xchars = extract_char_sequences(self.Xtokens)\n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              # Generator function yielding one batch after another. Batches are lists of lists\n",
        "\n",
        "              assert(len(self.Xtokens) == len(self.Ytokens) == len(self.Xpos) == len(self.Xchars))\n",
        "\n",
        "              N = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              # Data ordering\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              # batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend]\n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)\n",
        "\n",
        "                 # Pad sequences (tokens, NER tags, POS tags)\n",
        "                 seqX = [pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqPOS = [pad_sequence(self.Xpos[idx], batch_len, self.pad_token) for idx in batch_idxes]\n",
        "\n",
        "                 # Encode sequences (tokens, NER tags, POS tags)\n",
        "                 seqX = [code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqY = [code_sequence(seq,self.output_sym2idx) for seq in seqY]\n",
        "                 seqPOS = [code_sequence(seq, self.pos_sym2idx, self.unk_token) for seq in seqPOS]\n",
        "                 #print(seqX, seqY, seqPOS)\n",
        "\n",
        "                 # Character sequences\n",
        "                 char_batch = []\n",
        "                 for i in batch_idxes:\n",
        "                   char_sequences = self.Xchars[i]  # list of character sequences for each token in a sentence\n",
        "                   padded_char_sequences = [pad_sequence(char_seq, pad_size=15, pad_token=self.pad_token) for char_seq in char_sequences]\n",
        "                   encoded_char_sequences = [code_sequence(char_seq, self.char_sym2idx, self.unk_token) for char_seq in padded_char_sequences]\n",
        "                   char_batch.append(encoded_char_sequences)\n",
        "\n",
        "                 # Pad character sequences for each word in the sentence\n",
        "                 max_sent_len = batch_len\n",
        "                 max_word_len = 15\n",
        "                 # Ensure all sentences in the batch have the same length for character sequences\n",
        "                 seqChar = [pad_sequence(char_seq, max_sent_len, [self.char_sym2idx[self.pad_token]] * max_word_len) for char_seq in char_batch]\n",
        "\n",
        "                 assert(len(seqX) == len(seqY) == len(seqPOS) == len(seqChar))\n",
        "                 yield (seqX,seqY,seqPOS, seqChar)\n",
        "                 bstart += batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lp1H8gvrES1"
      },
      "source": [
        "# Improved NER Tagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x0P_l7MEfvN"
      },
      "outputs": [],
      "source": [
        "# NEW NER Tagger\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "    def __init__(self, traingenerator, embedding_size, hidden_size, pos_embedding_size, char_embedding_size, cnn_filters, device='cuda'):\n",
        "        super(NERtagger, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.pos_embedding_size = pos_embedding_size\n",
        "        self.char_embedding_size = char_embedding_size\n",
        "        self.cnn_filters = cnn_filters\n",
        "        self.allocate_params(traingenerator, device)\n",
        "\n",
        "    def allocate_params(self, datagenerator, device):\n",
        "        # Vocabulary and output sizes\n",
        "        vocab_size = len(datagenerator.input_sym2idx)\n",
        "        num_classes = len(datagenerator.output_sym2idx)\n",
        "        pos_vocab_size = len(datagenerator.pos_sym2idx)\n",
        "        char_vocab_size = len(datagenerator.char_sym2idx)\n",
        "\n",
        "        # Token embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, self.embedding_size, padding_idx=datagenerator.input_sym2idx[datagenerator.pad_token]).to(device)\n",
        "\n",
        "        # POS embeddings\n",
        "        self.pos_embedding = nn.Embedding(pos_vocab_size, self.pos_embedding_size, padding_idx=datagenerator.pos_sym2idx[datagenerator.pad_token]).to(device)\n",
        "\n",
        "        # Character embeddings and CNN (1D convolution)\n",
        "        self.char_embedding = nn.Embedding(char_vocab_size, self.char_embedding_size, padding_idx=datagenerator.char_sym2idx[datagenerator.pad_token]).to(device)\n",
        "        self.char_cnn = nn.Conv1d(self.char_embedding_size, self.cnn_filters, kernel_size=3, padding=1).to(device)\n",
        "\n",
        "        # Bi-LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_size + self.pos_embedding_size + self.cnn_filters,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        ).to(device)\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.Linear(self.hidden_size * 2, 1, bias=False).to(device)\n",
        "\n",
        "        # Output layer\n",
        "        self.linear = nn.Linear(self.hidden_size * 2, num_classes).to(device)\n",
        "\n",
        "    def compute_attention(self, lstm_out):\n",
        "        # lstm_out: (batch_size, seq_len, hidden_size * 2)\n",
        "        attention_scores = self.attention(lstm_out)  # Shape: (batch_size, seq_len, 1)\n",
        "        attention_weights = torch.softmax(attention_scores, dim=1)  # Shape: (batch_size, seq_len, 1)\n",
        "        context = torch.sum(attention_weights * lstm_out, dim=1)  # Shape: (batch_size, hidden_size * 2)\n",
        "        return context\n",
        "\n",
        "    def forward(self, Xinput, Xpos, Xchar):\n",
        "        # Embedding layers\n",
        "        token_embeddings = self.embedding(Xinput)  # Shape: (batch_size, seq_len, embedding_size)\n",
        "        pos_embeddings = self.pos_embedding(Xpos)  # Shape: (batch_size, seq_len, pos_embedding_size)\n",
        "\n",
        "        # Character embeddings + CNN\n",
        "        batch_size, seq_len, word_len = Xchar.shape\n",
        "        Xchar_flat = Xchar.view(-1, word_len)  # Shape: (batch_size * seq_len, word_len)\n",
        "        char_embeddings = self.char_embedding(Xchar_flat).permute(0, 2, 1)  # Shape: (batch_size * seq_len, char_embedding_size, word_len)\n",
        "        char_features = torch.relu(self.char_cnn(char_embeddings))  # Shape: (batch_size * seq_len, cnn_filters, word_len)\n",
        "        # max pooling operation\n",
        "        char_features = torch.max(char_features, dim=2).values  # Shape: (batch_size * seq_len, cnn_filters)\n",
        "        char_features = char_features.view(batch_size, seq_len, -1)  # Shape: (batch_size, seq_len, cnn_filters)\n",
        "\n",
        "        # Concatenate features\n",
        "        embeddings = torch.cat([token_embeddings, pos_embeddings, char_features], dim=2)  # Shape: (batch_size, seq_len, embedding_size + pos_embedding_size + cnn_filters)\n",
        "\n",
        "        # Bi-LSTM\n",
        "        lstm_out, _ = self.lstm(embeddings)  # Shape: (batch_size, seq_len, hidden_size * 2)\n",
        "\n",
        "        # Attention\n",
        "        context = self.compute_attention(lstm_out)  # Shape: (batch_size, hidden_size * 2)\n",
        "\n",
        "        # Output Layer\n",
        "        logits = self.linear(lstm_out)  # Shape: (batch_size, seq_len, num_classes)\n",
        "        return logits\n",
        "\n",
        "    def train_model(self, traingenerator, validgenerator, epochs, batch_size, device='cuda', learning_rate=0.001):\n",
        "        self.minloss = float('inf')\n",
        "        self.to(device)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "            self.train()\n",
        "            batch_losses, batch_accuracies = [], []\n",
        "\n",
        "            for seqX, seqY, seqPOS, seqChar in traingenerator.generate_batches(batch_size):\n",
        "                X = torch.LongTensor(seqX).to(device)\n",
        "                Y = torch.LongTensor(seqY).to(device)\n",
        "                POS = torch.LongTensor(seqPOS).to(device)\n",
        "                CHAR = torch.LongTensor(seqChar).to(device)\n",
        "\n",
        "                Yhat = self.forward(X, POS, CHAR)\n",
        "\n",
        "                # Flatten for loss computation\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "                # Backpropagation\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Compute accuracy\n",
        "                mask = (Y != pad_index)\n",
        "                Yargmax = torch.argmax(Yhat, dim=1)\n",
        "                correct = torch.sum((Yargmax == Y) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "            # Epoch summary\n",
        "            train_loss = sum(batch_losses) / len(batch_losses)\n",
        "            train_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
        "            print(f\"[train] Epoch {epoch} mean loss = {train_loss:.4f} | mean accuracy = {train_accuracy:.4f}\")\n",
        "\n",
        "            valid_loss, valid_accuracy = self.validate(validgenerator, batch_size, device, save_min_model=True)\n",
        "            print(f\"[valid] Epoch {epoch} mean loss = {valid_loss:.4f} | mean accuracy = {valid_accuracy:.4f}\")\n",
        "\n",
        "    def validate(self, datagenerator, batch_size, device='cuda', save_min_model=False):\n",
        "        batch_losses, batch_accuracies = [], []\n",
        "        pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for seqX, seqY, seqPOS, seqChar in datagenerator.generate_batches(batch_size):\n",
        "            with torch.no_grad():\n",
        "                X = torch.LongTensor(seqX).to(device)\n",
        "                Y = torch.LongTensor(seqY).to(device)\n",
        "                POS = torch.LongTensor(seqPOS).to(device)\n",
        "                CHAR = torch.LongTensor(seqChar).to(device)\n",
        "\n",
        "                Yhat = self.forward(X, POS, CHAR)\n",
        "\n",
        "                # Flatten for loss computation\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "                # Compute accuracy\n",
        "                mask = (Y != pad_index)\n",
        "                Yargmax = torch.argmax(Yhat, dim=1)\n",
        "                correct = torch.sum((Yargmax == Y) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "        # Validation summary\n",
        "        valid_loss = sum(batch_losses) / len(batch_losses)\n",
        "        valid_accuracy = sum(batch_accuracies) / len(batch_accuracies)\n",
        "\n",
        "        if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "        return valid_loss, valid_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g75tHG4DNgdR",
        "outputId": "f69695c5-3478-427b-b0b0-b3b8b723219d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/13\n",
            "[train] Epoch 1 mean loss = 0.8721 | mean accuracy = 0.7670\n",
            "[valid] Epoch 1 mean loss = 0.5775 | mean accuracy = 0.8145\n",
            "\n",
            "Epoch 2/13\n",
            "[train] Epoch 2 mean loss = 0.4182 | mean accuracy = 0.8625\n",
            "[valid] Epoch 2 mean loss = 0.4084 | mean accuracy = 0.8557\n",
            "\n",
            "Epoch 3/13\n",
            "[train] Epoch 3 mean loss = 0.2785 | mean accuracy = 0.9116\n",
            "[valid] Epoch 3 mean loss = 0.2738 | mean accuracy = 0.9194\n",
            "\n",
            "Epoch 4/13\n",
            "[train] Epoch 4 mean loss = 0.2009 | mean accuracy = 0.9389\n",
            "[valid] Epoch 4 mean loss = 0.2088 | mean accuracy = 0.9377\n",
            "\n",
            "Epoch 5/13\n",
            "[train] Epoch 5 mean loss = 0.1463 | mean accuracy = 0.9549\n",
            "[valid] Epoch 5 mean loss = 0.1897 | mean accuracy = 0.9424\n",
            "\n",
            "Epoch 6/13\n",
            "[train] Epoch 6 mean loss = 0.1001 | mean accuracy = 0.9693\n",
            "[valid] Epoch 6 mean loss = 0.1543 | mean accuracy = 0.9547\n",
            "\n",
            "Epoch 7/13\n",
            "[train] Epoch 7 mean loss = 0.0696 | mean accuracy = 0.9792\n",
            "[valid] Epoch 7 mean loss = 0.1386 | mean accuracy = 0.9577\n",
            "\n",
            "Epoch 8/13\n",
            "[train] Epoch 8 mean loss = 0.0479 | mean accuracy = 0.9860\n",
            "[valid] Epoch 8 mean loss = 0.1317 | mean accuracy = 0.9607\n",
            "\n",
            "Epoch 9/13\n",
            "[train] Epoch 9 mean loss = 0.0317 | mean accuracy = 0.9906\n",
            "[valid] Epoch 9 mean loss = 0.1279 | mean accuracy = 0.9634\n",
            "\n",
            "Epoch 10/13\n",
            "[train] Epoch 10 mean loss = 0.0208 | mean accuracy = 0.9940\n",
            "[valid] Epoch 10 mean loss = 0.1353 | mean accuracy = 0.9621\n",
            "\n",
            "Epoch 11/13\n",
            "[train] Epoch 11 mean loss = 0.0135 | mean accuracy = 0.9965\n",
            "[valid] Epoch 11 mean loss = 0.1379 | mean accuracy = 0.9631\n",
            "\n",
            "Epoch 12/13\n",
            "[train] Epoch 12 mean loss = 0.0087 | mean accuracy = 0.9977\n",
            "[valid] Epoch 12 mean loss = 0.1369 | mean accuracy = 0.9659\n",
            "\n",
            "Epoch 13/13\n",
            "[train] Epoch 13 mean loss = 0.0058 | mean accuracy = 0.9984\n",
            "[valid] Epoch 13 mean loss = 0.1503 | mean accuracy = 0.9642\n"
          ]
        }
      ],
      "source": [
        "# Train on the full dataset\n",
        "trainset_i = DataGenerator('eng.train')\n",
        "validset_i = DataGenerator('eng.testa',parentgenerator = trainset_i)\n",
        "tagger_i = NERtagger(trainset_i,embedding_size=64,hidden_size=128,pos_embedding_size=32,char_embedding_size=25,cnn_filters=30,device='cuda')\n",
        "tagger_i.train_model(traingenerator=trainset_i,validgenerator=validset_i,epochs=13,batch_size=64,device='cuda',learning_rate=0.0001847)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QKAJABz649A"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "**Hyperparameters search**\n",
        "We used the hyperparameter optimization framework Optuna and we searched for the best configuration of hyperparameters by minimizing the validation loss.\n",
        "\n",
        "The best configuration found is: {'embedding_size': 64, 'hidden_size': 128, 'learning_rate': 0.0001847078780156269, 'batch_size': 64} with the best validation loss: 0.23.\n",
        "\n",
        "The training results are as follows:\\\n",
        "The train loss: 0.0535\\\n",
        "Tthe train accuracy: 98.50%\\\n",
        "The validation results are as follows:\\\n",
        "The valid loss: 0.2172\\\n",
        "The valid accuracy: 93.58%\n",
        "\n",
        "The model maintains a reasonably good balance between memorizing training data and generalizing to unseen validation data. The difference between the validation accuracy (93.58%) and the training accuracy (98.50%) is 5%, indicating minor overfitting but still reasonable generalizability.\n",
        "\n",
        "**NER Tagger improvements**\n",
        "\n",
        "1) **Attention layer.** We added an attention layer to enhance the model's focus on key parts of the input sequence. This layer takes the Bi-LSTM output and produces a single attention score for each token. The softmax function is used to normalize these scores into `attention_weights`. The `context` vector then is computed as a weighted sum of the Bi-LSTM outputs, providing a richer representation in the `forward()` method.\n",
        "\n",
        "2) **Part-of-speech (POS) tags embeddings.** We incorporated part-of-speech tag embeddings as additional inputs. First a separate embedding layer is defined for the POS tags, then in the `forward()` method POS tags are embedded using the POS embedding layer, and finally POS embeddings are concatenated with the token embeddings and character-level features.\n",
        "\n",
        "3) **Character-level embeddings with Convolutional module for Unknown words.** To handle unknown words, we used a convolutional neural network (CNN) over character embeddings. First an embedding for each character in the vocabulary is created, then it is passed through the convolutional neural network CNN that applies filters to extract meaningful subword caracter-level features. As a result the model can generate an embedding for an unknown word by combining the features learned from its characters.\n",
        "\n",
        "**Results**\n",
        "With the improved model the best validation loss was achieved at the Epoch 9: 0.1279.\n",
        "The train accuracy achieved is 99.06%.\n",
        "The valid accuracy achieved is 96.34%.\n",
        "After improvements the valid accuracy increased by 2.76% from 93.58% to 96.34%. These results demonstrate that the implementation of the attention mechanism, of the POS tag embeddings, and of the convolutional word embedding module improved the NER Tagger model's ability to generalize and accurately recognize named entities, making it more efficient.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
